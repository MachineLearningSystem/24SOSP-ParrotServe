
	
	A.L. Gallo, P. Román]Andrea L. Gallo, Pablo Román
	March 30, 2023
	
	2020 Mathematics Subject Classification. Primary 33C45.
	Partially supported by CONICET, FONCyT and SECyT-UNC
	
	
		We study algebras of differential and difference operators acting on matrix valued orthogonal polynomials (MVOPs) with respect to a weight matrix of the form  W^(ν)_ϕ(x) = x^νe^-ϕ(x) W^(ν)_pol(x), where ν>0, W^(ν)_pol(x) is certain matrix valued polynomial and ϕ an entire function. We introduce a pair differential operators 𝒟, 𝒟^† which are mutually adjoint with respect to the matrix inner product induced by W^(ν)_ϕ(x). We prove that the Lie algebra generated by 𝒟 and 𝒟^† is finite dimensional if and only if ϕ is a polynomial, giving a partial answer to a problem by M. Ismail. In the case ϕ polynomial, we describe the structure of this Lie algebra.  The case ϕ(x)=x, is discussed in detail. We derive difference and differential relations for the MVOPs. We give explicit expressions for the entries of the MVOPs in terms of classical Laguerre and Dual Hahn polynomials.
	
	
	Lie algebras of differential operators for Matrix valued Laguerre type polynomials
    [
    
==================================================================================



§ INTRODUCTION

	The theory of matrix valued orthogonal polynomials (MVOPs) was initiated by Krein 1940s, and it has since been used in various areas of mathematics and mathematical physics. These areas include spectral theory, scattering theory, tiling problems, integrable systems, and stochastic processes. For further details and insights on these subjects, refer to <cit.>, <cit.>, <cit.>, <cit.>, <cit.>, <cit.>, and the references therein.
	
	Significant progress has been made in the past two decades towards understanding how the differential and algebraic properties of classical scalar orthogonal polynomials can be extended to the matrix valued setting. A fundamental role has been played by the connection between harmonic analysis of matrix valued functions on compact symmetric pairs and matrix valued orthogonal polynomials. In <cit.>, A. Durán poses the problem of determining families of MVOPs which are eigenfunctions of a suitable second order differential operator. In the scalar case, the answer to this problem is a classical result due to Bochner <cit.>. The only families with this property are those of Hermite, Laguerre and Jacobi. The matrix valued setting turns out to be much more involved. The first explicit examples appeared in connection with spherical functions of the compact symmetric pair (SU(3),U(2)). Following <cit.>, a direct approach was taken in <cit.>, <cit.> for the case of (SU(2) ×SU(2), diag), leading to a general set-up in the context of multiplicity free pairs <cit.>. In this context, certain properties of the orthogonal polynomials, such as orthogonality, recurrence relations, and differential equations, are understood in terms of the representation theory of the corresponding symmetric spaces. Recently, Casper and Yakimov developed a framework in <cit.> to solve the matrix Bochner problem. This involves the classification of all N × N weight matrix W(x) whose associated MVOPs are eigenfunctions of a second-order differential operator.
	
	
	
	Given N ∈ℕ we consider a matrix valued function W: [a,b] → M_N(ℂ) such that W(x) is positive definite for all x∈ [a,b] and W has finite moments of all order. In such a case, we say that W is a weight function,  which induces matrix valued inner product
	
    ⟨ P,Q ⟩=∫_a^b P(x)W(x)Q(x)^*dx ∈ M_N(),

	such that for all P,Q,R∈ M_N()[x], T∈ M_N(C) and a,b∈ℂ 
	the following properties are satisfied
	
    ⟨ aP+bQ,R⟩=a⟨ P,R⟩+b⟨ Q,R⟩,     ⟨ TP,Q⟩=T⟨ P,Q⟩, ⟨ P,Q⟩^*=⟨ Q,P⟩.

	Moreover ⟨ P,P ⟩ = 0 if and only if P=0. Using standard arguments, it can be shown that there exists a unique sequence (P(x,n))_n monic MVOPs with respect to W in the following sense:
	
    ⟨ P(x,n), P(x,m)⟩ = ℋ(n) δ_n,m.

	where the squared norm ℋ(n) is a positive definite matrix.
	
	
	By orthogonality, the polynomials P(x,n)'s satisfy the following three-term recurrence
	relation:
	
    xP(x,n) = P(x,n+1) + B(n) P(x,n) + C(n) P(x,n-1)

	where B(n), C(n) ∈ M_N(ℂ) and n ≥ 1.
	Notice that B(n) and C(n) satisfy 
	
    B(n)=X(n)-X(n+1),    C(n)= ℋ(n) ℋ(n-1)^-1,

	where  X(n) is the one-but-leading coefficient of P(x,n) and ℋ(n) as in (<ref>).
	Moreover, for n ≥ 2, let Y(n) denotes the second-but-leading coefficient of P(x,n). Then
	
    Y(n)=Y(n+1)+B(n)X(n)+C(n).

	
	In <cit.>, the authors studied difference–differential relations for a specific class of MVOPs associated with the weight W(x)=e^-v(x)e^xAe^xA^∗, where x ∈ℝ, v(x) is a scalar polynomial of even degree, and A is a constant matrix. There is a way of obtaining information about the matrix orthogonal polynomials by investigating two mutually adjoint operators 𝒟 and 𝒟^†. If v(x) is a polynomial of degree two, in addition to 𝒟 and 𝒟^†, there exists a second order differential operator D having the MVOPs as eigenfunctions. It turns out that 𝒟, 𝒟^† and D generate a finite dimensional Lie algebra which is isomorphic to the Lie algebra of the oscillator group. The Casimir operator for this algebra is given explicitly and used to obtain information of the MVOPs.
	In this work, we solve the analogous problem for Laguerre-type weights. This case is more involved than the previous one due to the structure of the associated Lie algebra and the non-diagonality of certain formulas that involve W.
	
	In the scalar case, this problem is closely related to <cit.>. Here Ismail proposed to study the finite dimensionality of certain Lie algebra generated by a pair of differential operators which are mutually adjoint respect to a Laguerre-type weight. More precisely, given the scalar weight w_1(x)=x^αe^-ϕ(x) with x>0,  α>1 and differential operators
	
    𝒟_1,n=x∂_x +x B_n(x),     𝒟_2,n=-x∂_x + x B_n(x)+xϕ'(x),

	where {B_n} is a sequence of scalar polynomials, the problem asks to prove that “The Lie algebra generated by 𝒟_1,n and 𝒟_2,n is finite dimensional if and 	only if ϕ is a polynomial”.
	
	In this paper we provide a partial answer to this problem in the context of matrix valued orthogonal polynomials. We give an explicit matrix valued weight W^(ν)_ϕ(x) =x^ν e^-ϕ(x) W^(ν)_pol(x), where W^(ν)_pol(x) is a matrix polynomial depending on ν, and differential operators 
	
    𝒟 = ∂_x x + x(A-1),   𝒟^† = -∂_x x - (1+ν+J)+xϕ'(x)-x.
 
	In this case, we prove that the Lie algebra generated by is finite dimensional if and only if ϕ is a polynomial.	As a consequence, this solves <cit.> when B_n(x)=-1 for all n∈ℕ.
	
	

 §.§ Outline and main results

	
	In Section 2 we recall some preliminaries. In particular, we introduce the left and right Fourier algebras related to the sequence of monic MVOPs.
	
	In Section 3 for a given analytic function ϕ on a neighborhood of the interval [0,∞), we introduce a Laguerre type weight W^(ν)_ϕ and the operators 𝒟 , 𝒟^† and prove that they are mutually adjoint with respect to W^(ν)_ϕ(x). For the MVOPs {P_n} respect to W^(ν)_ϕ,
	we find discrete operators M,  M^† associated to 𝒟, 𝒟^† respectively, given by the relations M · P_n = P_n ·𝒟 and M^†· P_n = P_n ·𝒟^†.
	
	In Section 4 we study the Lie algebra 𝔤_ϕ generated by the differential operators 𝒟, 𝒟^†. We prove that 𝔤_ϕ is finite dimensional if and only if ϕ is a polynomial. Also, for this family of Lie algebras {𝔤_ϕ} we obtain that 𝔤_ϕ=ℂ^2⊕𝔥 and 𝔥 is a solvable Lie algebra with nilradical of codimension one. Moreover, we obtain a classification of this family of Lie algebra up to isomorphisms.
	
	In Section 5 we give an explicitly expression for 𝒟, 𝒟^†, M and M^† in the case ϕ(x)=x.	In this case, we also find a symmetric second-order differential operator D which have {P_n} as eigenfunctions. We describe the Lie algebra 𝒜 generated by 𝒟, 𝒟^† and D, 𝒜=𝒵_𝒜⊕ [𝒜,𝒜] where 𝒵_𝒜=2 and [𝒜,𝒜] is isomorphic to SL(2,ℂ). Also, we obtain some relations between ℋ_n, B_n and C_n. 
	
	In Section 6, we consider the polynomials R(x,n)=K_n P(x,n)e^xA 
	where P(x,n) are the MVOPs associated with the weight W^(ν) and
	K_n certain lower triangular matrices. Using the operator D,
	we show that the matrix entries of R_n can be put in terms of 
	generalized Laguerre polynomials  and a family of constants ξ(n,i,j)'s. 
	Finally, we give two-terms recursions for the constants ξ(n,i,j)'s 
	and for the squared norm ℋ_n.
	
	Finally, in Section 7, in the case A=- ∑_k=1^N-1 E_k+1,k, and δ^k>0 
	satisfying two non-linear conditions (related to Pearson's equations),  we show that the constants ξ(n,i,j)'s are written in terms of dual Hanh polynomials.
	
	

§ PRELIMINARIES

	
	
	
	This section presents the left and right Fourier algebras associated with the sequence of monic MVOPs, as developed by Casper and Yakimov in <cit.>. The results discussed in this section have been previously covered in a more comprehensive context in <cit.>.
	
	Let Q(x,n) be a function Q:ℂ×ℕ_0 → M_N(ℂ) such that Q(x,n) is a rational function of x for fixed n. A differential operator of the form
	
    =∑_j=0^n ∂_x^j F_j(x),     ∂_x^j := d^jdx^j,

	where F_j:ℂ→ M_N(ℂ) is a rational function of x, acts on Q from the right by
	
    (Q·)(x,n)  = ∑_j=0^n (∂_x^jQ)(x,n)   F_j(x).

	
	The algebra of all differential operators of the form (<ref>) will be denoted by ℳ_N.  In addition to the right action by differential operators, we also consider a left action on Q by difference operators on the variable n. For j∈ℤ, let δ^j be the discrete operator which acts on a sequence A:ℕ_0 → M_N(ℂ) by
	
    (δ^j · A)(n)=A(n+j).

	Here we assume that the value of a sequence at a negative integer is equal to zero. For given sequences A_-ℓ,…,A_k, a discrete operator of the form
	
    M=∑_j=-ℓ^k A_j(n) δ^j,

	acts on Q from the left by
	
    (M · Q)(x,n)    = ∑_j=-ℓ^k A_j(n)   (δ^j· Q)(x,n) = ∑_j=-ℓ^k A_j(n)   Q(x,n+j).

	
	We shall denote the algebra of difference operators (<ref>) by 𝒩_N. As in <cit.> we define:
	
		The left and right Fourier algebras are given by:
		
    ℱ_L(P)   ={ M∈𝒩_N ∃ ∈ℳ_N,  M· P = P·}⊂𝒩_N,
    ℱ_R(P)   ={∈ℳ_N ∃  M∈𝒩_N,  M· P = P·}⊂ℳ_N.

	
	
	The definition of the Fourier algebras directly implies a connection between the elements of ℱ_L(P) and ℱ_R(P). Moreover, the map
	
    φℱ_L(P) →ℱ_R(P),     defined by    M· P = P ·φ(M),

	is an algebra isomorphism. In <cit.> this map is called the generalized Fourier map. More precisely, M_1M_2· P = P ·φ(M_1)φ(M_2) for all M_1,M_2∈ℱ_L(P). On the other hand, by the definition of φ, we have that M_1M_2· P = P·φ(M_1M_2).
	
	
		
		In this context, the three term recurrence relation (<ref>) can be written as
		
    xP = P· x = L· P,     where    L=δ + B(n) + C(n)δ^-1.

		Therefore x∈ℱ_R, L∈ℱ_L and φ(L)=x. For every polynomial v ∈ℂ[x], we have
		
    P· v(x) =P· v(φ(L))= v(L)· P.

	
	
	On of the crucial results from <cit.> is the existence of an adjoint operation † in the Fourier algebras ℱ_L(P) and ℱ_R(P) as described in <cit.>. To define the adjoint operation in ℱ_L(P), we initially observe that the algebra of difference operators 𝒩_N has a ∗-operation defined as follows:
	
    ( ∑_j=-ℓ^k A_j(n)  δ^j )^∗ = ∑_j=-ℓ^k A_j(n-j)^∗ δ^-j,

	where A_j(n-j)^∗ is the conjugate transpose of A_j(n-j). Now, the adjoint of M∈𝒩_N is given by 
	
    M^† = ℋ(n) M^∗ℋ(n)^-1,

	where ℋ(n) is the squared norm which we view as an difference operator of order zero. The following holds:
	
    ⟨ (M· P)(x,n),P(x,m)⟩ = ⟨ P(x,n),(M^†· P)(x,m)⟩.

	
	In <cit.> the authors show that every differential operator D∈ℱ_R(P) has a unique adjoint ^†∈ℱ_R(P) with the property
	
    ⟨ P·, Q ⟩ = ⟨ P,Q·^†⟩,

	for all P,Q∈ M_N(ℂ)[x]. Moreover, φ(M^†) = φ(M)^† for all M∈ℱ_L(P).
	
	
	

§ SEMI-CLASSICAL LAGUERRE TYPE SOLUTIONS

	
	
	In the sequel, we consider the following two matrices A,J∈ M_N(ℝ) which satisfy
	
    J=∑_k=1^N k E_k,k     A =∑_k=1^N-1 a_k E_k+1,k.

	Notice that, it is straightforward to show that
	
    [J,A]=A   and   e^xAJ e^-xA=J-Ax.

	Let us consider the following weight matrix supported on the interval [0,∞):
	
    W^(ν)_ϕ(x) = e^Ax T^(ν)_ϕ(x) e^A^∗ x,     T^(ν)_ϕ(x) =  e^-ϕ(x)∑_k=1^N δ^(ν)_k x^ν+k  E_k,k,

	where δ^(ν)_k is a constant real number for 1 ≤ k ≤ N, and ϕ be an analytic function on a neighborhood of the interval [0,∞).
	In the sequel, we assume that W(x)P(x) = 0 has vanishing limits at the endpoints of support for any matrix polynomial P.
	
	
	
		Let A,J∈ M_N(ℂ) as in (<ref>). 
		Then, the first order differential operators
		
    𝒟 = ∂_x x + x(A-1),   𝒟^† = -∂_x x - (1+ν+J)+xϕ'(x)-x,

		are mutually adjoint.
	
	
		Let P,Q ∈ M_N(ℂ[x]). 
		In order to simplify notation, in the rest of the proof, we denote by W(x):=W^(ν)_ϕ(x) and T(x)=W^(ν)_ϕ(x)
		
    ⟨ P ·𝒟, Q ⟩   =   ∫_0^∞ (P·𝒟) W(x) Q^∗(x) dx
       =   ∫_0^∞( xP'(x)+xP(x)(A-1) ) W(x) Q^∗(x) dx.
    
		Notice that, since W(x)P(x) has vanishing limits at the endpoints x=0, and x=∞, integration by parts implies that
		
    ∫_0^∞ xP'(x)W(x)Q^∗(x)dx = -∫_0^∞ P(x) (xW(x)Q^∗(x) )'  dx.

		On the other hand, we have that
		
    ∫_0^∞ xP(x)(A-1)W(x) Q^∗(x) dx=∫_0^∞ P(x)W(x) ( W^-1(x) x (A-1)W(x) )Q^∗ (x)  dx,

		by linearity we obtain that
		
    ⟨ P ·𝒟, Q ⟩   =    - ∫_0^∞ P(x) (xW(x)Q^∗(x) )'  dx + ∫_0^∞ P(x)W(x) ( W^-1(x) x (A-1)W(x) )Q^∗ (x) dx
       =    -∫_0^∞ P(x)(W(x)Q^∗(x) +x W'(x) Q^∗+xW(x)(Q^∗(x))') dx
          + ∫_0^∞ P(x)W(x) ( W^-1(x) x (A-1)W(x) )Q^∗ (x) dx.

		Notice that since  (Q · (1+x∂_x) )^∗(x)=Q^∗(x)+x(Q^∗(x))', 
		we can put
		
    ∫_0^∞ P(x)(W(x)Q^∗(x) +W(x)x(Q^∗(x))') dx=∫_0^∞ P(x)W(x)(Q · (1+x∂_x) )^∗(x)  dx.

		On the other hand,
		
    ∫_0^∞ P(x) x W'(x) Q^∗(x) dx=∫_0^∞ P(x) W(x) xW^-1(x) W'(x) Q^∗(x) dx.

		Hence, we obtain that
		
    ⟨ P ·𝒟, Q ⟩   =    - ∫_0^∞ P(x)W(x)(Q · (1+x∂_x) )^∗(x)  dx - ∫_0^∞ P(x) W(x) xW^-1(x) W'(x) Q^∗(x) dx
          + ∫_0^∞ P(x)W(x) ( W^-1(x) x (A-1)W(x) )Q^∗ (x) dx.

		By (<ref>) we have that
		
    W^-1(x) W'(x)    =e^-A^∗ x(T^-1(x) A  T(x)+T ^-1(x)T'(x)+ A^∗) e^A^∗ x,
    
    			W^-1(x) x (A-1)W(x)    = e^-A^∗x(x T^-1(x)  A  T(x)  - x)e^A^∗x.

		Thus, we obtain 
		
    ⟨ P ·𝒟, Q ⟩   =    - ∫_0^∞ P(x)W(x)(Q · (1+x∂_x) )^∗(x)  dx
          - ∫_0^∞ P(x) W(x)  e^-A^∗ x(xT^-1(x)  A   T(x)+x T^-1(x)T'(x)+ x A^∗) e^A^∗ x Q^∗(x) dx
          + ∫_0^∞ P(x)W(x) e^-A^∗x(x T^-1(x)  A  T(x)  - x)e^A^∗x Q^∗(x)dx
       =    - ∫_0^∞ P(x)W(x)(Q · (1+x∂_x) )^∗(x)  dx
          - ∫_0^∞ P(x) W(x)  e^-A^∗ x(x T^-1(x)T'(x)+ x A^∗+x) e^A^∗ x Q^∗(x) dx.

		By taking into account that xT'(x)=T(x) (-xϕ'(x)+ν+J), we obtain that
		
    ⟨  P ·𝒟, Q ⟩   =    - ∫_0^∞ P(x)W(x)(Q · (1+x∂_x) )^∗(x)  dx
       -   ∫_0^∞ P(x) W(x)  e^-A^∗ x ( -xϕ'(x)+ν+J+xA^∗+x) e^A^∗x Q^∗(x) dx.

		Notice that  the second expresion of the right hand of the above equality is
		
    e^-A^∗ x ( -xϕ'(x)+ν+J+xA^∗+x) e^A^∗x = -xϕ'(x)+ ν+ e^-A^∗ x J e^A^∗x+xA^∗+x.

		On the other hand, the equation e^xAJ e^-xA=J-Ax
		implies that e^-A^∗ x J e^A^∗x=J-A^∗x. Hence, we obtain that
		
		
    ⟨ P ·𝒟, Q ⟩   =    - ∫_0^∞ P(x)W(x)(Q · (1+x∂_x) )^∗(x)  dx
          - ∫_0^∞ P(x) W(x)   (x -xϕ'(x)+(ν+J-A^∗x+xA^∗) Q^∗(x) dx
       =   ∫_0^∞ P(x)W(x)(Q · -(x∂_x+x-xϕ'(x)+(ν+J+1) )^∗(x)  dx
       =   ⟨ P,Q·𝒟^†⟩.

		Therefore, the operators 𝒟 and 𝒟^† are mutually adjoint, as asserted.
	
	
	By the above theorem, since 𝒟 = ∂_x x + x(A-1) and
	𝒟^† = -∂_x x - (1+ν+J)+xϕ'(x)-x, then we obtain that
	
    𝒟^† = -𝒟 + (Ax-J) -(1+ν) + xϕ'(x)-2x.

	
	
		Let A,J∈ M_N(ℂ) be matrices as in (<ref>). 
		Then, 𝒞=Ax-J  is a symmetric operator respect to the weight W:=W^(ν)_ϕ as in (<ref>). 
		Moreover, if P(x,n)'s are monic MVOPs associated with the weight W, such that
		
    P·𝒞=M_𝒞· P,   then   M_𝒞=∑_i=-1^1 U_j(n)δ^j,

		with 
    U_1(n):=A,     U_0(n):=X(n)A-AX(n+1)-J,
 
    U_-1(n):= Y(n)A-AY(n+1) + [J,X(n)] + (AX(n+1)-X(n)A)X(n),
 
		where X(n) and Y(n) are the coefficients of the (n-1)-term and (n-2)-term of P(x,n) respectively.
	
	
		In the same manner as Proposition <ref>, it can be shown that 𝒞 is an symmetric operator respect with W.
		
		If we put M_𝒞=∑ U_j(n)δ^j such that P·𝒞=M_𝒞· P.
		By taking into account that 𝒞  increases the degree of any polynomial in 1, we obtain that U_j(n)=0 for j>1. On the other hand, since 𝒞 is an symmetric operator respect to W, we have that M_𝒞=M^†_𝒞 and so U_j(n)=0 for j<-1.
		
		The formulas for U_-1(n),U_0(n) and U_1(n) can be obtained by direct computation from P·𝒞=M_𝒞· P.
	
	
	
		Since 𝒞=Ax-J=(Ax-J)^†, then M_𝒞=M_𝒞^†.
		Thus, from equations (<ref>) we have that 
		
    U_1(n)    =ℋ(n) U_-1(n+1)^∗ℋ(n+1)^-1,
     
    			U_0(n)    =ℋ(n)U_0(n)^∗ℋ(n)^-1,

		and so we obtain that
		
    A=ℋ(n)(Y(n+1)A-AY(n+2)+[J,X(n+1)]+(AX(n+2)-X(n+1)A)X(n+1))^∗ℋ(n+1)^-1,

		
    X(n)A-AX(n+1)-J=ℋ(n) (X(n)A-AX(n+1)-J)^∗ℋ(n)^-1.
 
	
	
	
		Let W:=W^(ν)_ϕ be a matrix weight as in (<ref>), 
		with monic MVOPs P(x,n) such that
		
    𝒟= ∂_x x + (A-1)x,     𝒟^†= -𝒟 + 𝒞 + v'(x)

		for some polynomial v(x) of degree k and 𝒞=Ax-J. 
		If X(n) and Y(n) are the coefficients of the (n-1)-term and (n-2)-term of P(x,n) respectively. 
		Then, the monic polynomials P(x,n) satisfy the following relation
		
    P·𝒟=M· P,      M= ∑_j=-k+1^1 A_j(n)δ^j

		with 
		
    A_1(n)=A-1,   A_0(n)=n+X(n)A - A X(n+1)-B(n),
 
			
    A_-1(n)=(n-1)X(n)+Y(n)(A-1)-(A-1)Y(n+1)-A_0(n)X(n),

			
    A_j(n)=(v'(L))_j(n),    -k+1 <j< -1

		where B(n) is given by (<ref>).
	
	
		Clearly, the formulas for A_j(n) with j=-1,0,1 can be derived from the equalities in (<ref>) by using the definition of 𝒟.
		
		For j<-1, we have that
		
    A_j(n)    =   ⟨ P·𝒟,δ^j · P ⟩ℋ(n-j)^-1=⟨ P, δ^j · P ·𝒟^†⟩ℋ(n-j)^-1
        =   ⟨ P, δ^j · P · v'(x)⟩ℋ(n-j)^-1=⟨ P· v'(x), δ^j · P⟩ℋ(n-j)^-1
       =    ⟨ v'(L)· P, δ^j· P ⟩ℋ(n-j)^-1,

		where we have used that ⟨ P, δ^j · P·𝒟⟩ and ⟨ P, δ^j · P·𝒞⟩ are both zero for j<-1 in the third equality, and the fact that v'(x) is a scalar funtion in the fourth one. Then, we have that 
		
    A_j(n)= (v'(L))_j(n)   for j<-1.

		To complete the proof, notice that (v'(L))_j(n)=0 for j≤ -k.
	
	
	As a direct consequence, we obtain the following corollary.
	
		In the same hypothesis as in Theorem <ref>.
		If the polynomial v has degree 1, then the discrete operator M associated  with 𝒟 satisfies
		
    M=  A_0(n)+(A-1)δ

		with A_0(n) as in Theorem <ref>. Moreover, in this case we have that
		
    (n-1)X(n)+Y(n)(A-1)-(A-1)Y(n+1)-( n+X(n)A - A X(n+1)-B(n))X(n) = 0.

	
	
		By Theorem <ref>, 
		since (v) < 2 we obtain that A_j(n)=0 for all j<-1.
		On the other hand, notice that since v has degree 1, 
		then v'(x) is a constant function and so the operator
		𝒟^† does not increase degrees. 
		This implies that A_1^†=0 and therefore 
		
    A_-1(n)=(n-1)X(n)+Y(n)(A-1)-(A-1)Y(n+1)-A_0(n)X(n) = 0,
 
		the formula for A_1(n) and A_0(n) are consequence of Theorem <ref>.
	
	

§ LIE ALGEBRAS ASSOCIATED TO ORTHOGONAL POLYNOMIALS

	
	In this section, we solve a particular case of the problem proposed by Ismail in <cit.>, as described in the introduction. For this purpose, we study the structure of a Lie algebra related with the operators 𝒟 and 𝒟^†. 
	
	Recall that if 𝔤 is a finite dimensional Lie algebra, and if 𝔤^j and 𝔤_j denote the following recursions
	
    𝔤^0=𝔤_0=𝔤,   𝔤^j+1=[𝔤^j,𝔤^j]   and   𝔤_j+1=[𝔤,𝔤_j],

	then 𝔤 is called solvable (nilpotent) if 𝔤^j=0 for some j (if 𝔤_j=0 for some j).
	Clearly, any nilpotent Lie algebra is solvable.
	The radical (nilradical) of 𝔤 is its maximal solvable ideal (maximal nilpotent ideal) of 𝔤.
	We will denote by Rad(𝔤) and Nil(𝔤) to the radical and nilradical of 𝔤, respectively.
	
	
	

 §.§ Lie algebra generated by 𝒟 and 𝒟^†

	
	
	
		Let A,J∈ M_N(ℂ) as in (<ref>) and let ϕ an entire function over ℂ, let us consider the operators
		
    𝒟 = ∂_x x + x(A-1),   𝒟^† = -∂_x x - (1+ν+J)+xϕ'(x)-x.

		If x and x^jϕ^(j)(x)  act over matrix valued polynomials by right constant multiplication, then we have that 
		
    [𝒟,x] = -x,     [𝒟^†,x]=x,     [𝒟,𝒟^†] = -x^2ϕ^(2)(x)+(2-ϕ'(x))x,

		
    [𝒟,ϕ^(j)(x)x^j] =  -(jx^jϕ^(j)(x)+x^j+1ϕ^(j+1)(x)) = -[𝒟^†,ϕ^(j)(x)x]   for all j≥ 1.
	
	
	
	In the sequel, given ϕ an entire function over ℂ, we denote by
	
    𝔤_ϕ= ⟨ 1,𝒟, 𝒟^†, x, xϕ'(x), x^2ϕ^(2)(x),…⟩

	with bracket as above. We are interested in the case that this Lie algebra is finite dimensional. The following proposition states that this happens if and only if ϕ is a polynomial. We will need the following notation, given ϕ a polynomial over ℂ with ℓ non-zero coefficients
	
    k=ℓ+2    if ϕ'(0)=ϕ(0)=0,
    ℓ+1    if ϕ'(0)=0, ϕ(0)≠ 0,
    ℓ+1    if ϕ(0)=0, ϕ'(0)≠ 0,
    ℓ   if ϕ(0)≠ 0, ϕ'(0)≠ 0,
	
	
	
		Let ϕ an analitic function over ℂ and let 𝔤:=𝔤_ϕ its associated Lie algebra as in (<ref>). 
		Then, we have that
		(𝔤) is finite if and only if ϕ is a polynomial. 
		In such case, if k is as in (<ref>) then
		
    (𝔤)= k+2.

	
	
		Clearly, if ϕ is a polynomial, then the dimension of 𝔤 is finite, since if n is the degree of ϕ then ϕ^(m)(x)=0 for all m>n. 
		
		Conversely, assume now that ϕ is not a polynomial. 
		Since ϕ is analytic, we can express ϕ as follow
		
    ϕ(x)= ∑_i=0^∞ a_ix^i.

		This implies that 
		
    x^jϕ^(j)(x)= ∑_i=0^∞ b_i,j x^i,   with   b_i,j=
    			ijj!  a_i     if j≤ i, 
       
    				0     if i<j.

		In particular, if a_i=0 then b_i,j=0 for all j ∈ℕ.
		
		Let {i_t}_t∈ℕ be the sequence 
		of non-zero coefficients indices of ϕ, that is  i_t<i_t+1 for all t ∈ℕ, such that a_i ≠ 0 if and only if i= i_t for some t ∈ℕ. 
		
		
		Claim: The vector space ⟨ x^i_1ϕ^(i_1)(x),…, x^i_ℓϕ^(i_ℓ)(x)⟩ has dimension ℓ.
		
		Let c_1,…,c_ℓ∈ℂ such that 
		
    c_1x^i_1ϕ^(i_1)(x)+⋯+ c_ℓx^i_ℓϕ^(i_ℓ)(x)=0,

		this induces the following system of equations
		
    ∑_t=1^h c_ti_hi_t i_h! a_i_t=0   for h=1,…,ℓ.

		By taking into account that a_i_1≠ 0, 
		the equation for h=1 implies that c_1=0. 
		In the same way, since c_1=0, the equation for h=2 implies that
		c_2 a_i_2 i_2!=0 and so c_2=0 since a_i_2≠ 0. Inductively,
		if c_1=c_2=…=c_ℓ-1=0, then the equation for h=ℓ implies that
		c_ℓ a_i_ℓ i_ℓ!=0 and so c_ℓ=0 since a_i_ℓ≠ 0, 
		hence we obtain that c_h=0 for all h∈{1,…,ℓ}.
		
		By the claim, the space 𝔤 has subspaces of all of the possible dimensions and so is non-finite dimensional, as asserted.
		
		Now, assume that ϕ is a polynomial of degree n, in the same notation as above,
		by (<ref>) we have that 
		
    ⟨ xϕ'(x),x^2ϕ^(2)(x),…, x^nϕ^(n)(x)⟩⊆⟨ x^i_1,…,x^i_ℓ⟩.

		The claim and the above statement imply that ⟨ xϕ'(x),x^2ϕ^(2)(x),…, x^nϕ^(n)(x)⟩ has dimension ℓ. 
		
		Finally, the last assertion follows from the fact that
		𝒟,𝒟^† are linearly independent respect to
		
    ⟨ 1,x,xϕ'(x),x^2ϕ^(2)(x),…, x^nϕ^(n)(x)⟩
 
		and this vector space has dimension k, with k as in the statement.
	
	
	
		The above proposition solves the problem proposed by Ismail in <cit.> for the case B_n=-1 for all n natural number. In the notation of <cit.>, the differential operators 𝒟 and 𝒟^† correspond to 𝒟=x L_1,n and 𝒟^†=x L_2,n +(1+ν). Then, the algebra generated by {𝒟, 𝒟^†,1} is isomorphic to the algebra generated by {xL_1,n, xL_2,n,1}.
	
	
	
	
		By the proof of the above theorem,
		if ϕ(x)=a_0+a_1 x +…+ a_nx^n is a polynomial of degree n with ℓ non-zero coefficients.
		If {i_1,…,i_ℓ}⊆{0,…,n} is the set of indices such that a_i_j≠ 0.
		then we have that
		
    ⟨ xϕ'(x),x^2ϕ^(2)(x),…, x^nϕ^(n)(x)⟩=⟨ x^i_1,…,x^i_ℓ⟩.

	
	
	
	
		Let ϕ_1(x)=x^3 and ϕ_2(x)=x^3+x^2, by the above theorem the associated Lie algebras
		𝔤_ϕ_1 and 𝔤_ϕ_2 have the dimensions 5 and 6, respectively. Then, the algebras
		𝔤_ϕ_1 and 𝔤_ϕ_2 are non-isomorphic. 
	
	
	
	
		The element z= 𝒟+𝒟^† +2x -xϕ'(x) is a symmetric differential operator which
		belongs to the center of the Lie algebra 𝔤.
	
	
		It is follows immediately from the definition of the bracket of 𝔤_ϕ.
	
	
	
		The central element that we found in the above lemma, it is related with the symmetric operator 𝒞 that was considered in Lemma <ref>,
		we will see this in the following section.
	
	
	In the sequel, given a polynomial ϕ(x)=a_0+a_1 x+ ⋯ +a_n x^n  of degree n≥ 2 
	with ℓ non-zero coefficients and k as in (<ref>), let us consider the following notations. 
	
    I_ϕ={i ∈{2,…,n}: a_i≠ 0}={ j_1,…,j_k-2}=
    		{i_3,…,i_ℓ}   if a_0≠ 0, a_1≠ 0,
    {i_2,…,i_ℓ}   if a_0=0 and a_1≠ 0,
    {i_2,…,i_ℓ}   if a_0≠ 0 and a_1= 0,
    {i_1,…,i_ℓ}   if a_0=0 and a_1=0,

	with j_t< j_t+1 and i_t<i_t+1.
	
	
		Let ϕ(x)=a_0+a_1 x+ ⋯ +a_n x^n be a polynomial of degree n≥ 2 
		with ℓ non-zero coefficients and k as in (<ref>). 
		If 𝔤:=𝔤_ϕ is the associated Lie algebra of ϕ as in (<ref>),
		then we have that
		
    𝔤≅ℂ^2 ⊕𝔥

		where 𝔥  is a solvable Lie algebra of dimension k, with an abelian nilradical of dimension k-1. More precisely,
		if I_ϕ is as in (<ref>)	then
		
    𝔥≅⟨ E ⟩⋉⟨ E_1, … E_k-1⟩

		where ⟨ E_1, … E_k-1⟩ is abelian and the rest of the brackets satisfy
		
    [E,E_1]=E_1   and   [E,E_t]= j_t-1 E_t   for t=2,…,k-1.

	
	
		By Lemma <ref>, the element 
		z= 𝒟+𝒟^† +2x -xϕ'(x) belongs to the center of 𝔤, 
		and so we obtain an element in the center which does not belong to ⟨ 1⟩, 
		thus if 
		
    𝔥=⟨𝒟, x,xϕ'(x),x^2ϕ^(2)(x),…, x^nϕ^(n)(x) ⟩

		then we obtain that
		
    𝔤≅ℂ^2 ⊕𝔥,

		with 𝔥  a Lie algebra of dimension k.
		
		Thus, it is enough to show that 𝔥 is solvable with nilradical of dimension k-1. 
		Let us consider
		
    𝔨=⟨ x,xϕ'(x),x^2ϕ^(2)(x),…, x^nϕ^(n)(x)⟩,

		by definition of the bracket and by taking into account that 
		
    [x,x^lϕ^(l)(x)]=[x^i ϕ^(i)(x),x^j ϕ^(j)(x)]=0    for all i≠ j,

		we obtain that [𝔥,𝔥]⊆𝔨.
		Hence, by (<ref>) we obtain that [[𝔥,𝔥],[𝔥,𝔥]]=0,
		and so 𝔥 is solvable.
		Finally, notice that
		𝔨 is an abelian ideal of 𝔥 of dimension 
		
    (𝔨)= (𝔥)-1=k-1,

		this implies that 𝔨 is the nilradical of 𝔥, as desired.
		
		In the same manner as in Remark <ref> we have that
		
    𝔥=⟨𝒟, x, x^j_1,…, x^j_k-2⟩,
 
		in this case ⟨ x, x^j_1,…, x^j_k-2⟩ is an abelian subalgebra of dimension k-1. 
		It is enough to see the brackets [𝒟,x^j_t] and [𝒟,x], in this case we obtain that
		
    [𝒟,x]=-x     and     [𝒟,x^j_t]= -j_t x^j_t,

		so we obtain that ⟨ x, x^j_1,…, x^j_k-2⟩ is an abelian ideal. Finally, 
		if we consider the following correspondence
		
    𝒟⟼ -E,    x⟼ E_1,    x^j_i⟼ E_i+1  for i=1,…,k-2,

		is an Lie Algebra isomorphism between 𝔥 and ⟨ E ⟩⋉⟨ E_1, … E_k-1⟩ with brackets given as in (<ref>), as asserted.
	
	
	
	In the sequel we are going to study the structure of the solvable Lie algebra 𝔥_ϕ.
	In general, a Lie algebra 𝔥' with an abelian ideal of codimension 1 is called almost abelian.
	This kind of algebra was studied by V.V. Gorbatsevich in <cit.>. 
	The author asserted that in general this kind of algebra it decomposes as
	
    ℂ⋉_ψℂ^k-1,

	this semidirect product gives a linear transformation ψ: ℂ→ gl_k-1(ℂ),
	moreover he asserted that the structure of this kind of algebras it determines by the matrix Ψ=ψ(1). More precisely,
	
    ℂ⋉_ψℂ^k-1≅ℂ⋉_ψ'ℂ^k-1⟺  Ψ and Ψ' are conformally similar,

	recall that Ψ and Ψ' are conformally similar if and only if there exist a matrix P∈ Gl_k-1(ℂ) and a non-zero complex number λ∈ℂ∖{0} such that Ψ= λ P Ψ' P^-1.
	
	
		Let k be an integer greater than 1 and let 1<j_1<…<j_k-2 and 1<j'_1<…< j'_k-2 be two sequences of positive integers.
		Let us consider 
		
    Ψ = diag(1, j_1,…,j_k-2)   and  Ψ' = diag(1, j'_1,…,j'_k-2).
 
		Then, Ψ and Ψ' are conformally similar if and only if Ψ=Ψ'.
		
	
		Clearly, if Ψ=Ψ' then they are conformally similar trivially.
		
		Now, assume that Ψ and Ψ' are conformally similar, so there exist λ∈ℂ^* and P∈ GL_k-1(ℂ) such that
		
    Ψ' = λ P Ψ P^-1,
 
		by similarity we obtain the following spectral relationship
		
    Spec(Ψ')= λ·Spec(Ψ),

		i.e. all of the eigenvalues of Ψ' can be obtained from the eigenvalues of Ψ by multiplication by λ.
		Since Ψ and Ψ' are both diagonal, we have that 
		
    Spec(Ψ)={1,j_1,…,j_k-2}   and  Spec(Ψ')={1, j'_1,…,j'_k-2},
 
		since 1 belong to both spectra and the rest of the eigenvalues of Ψ and Ψ' are greater than 1, we obtain that λ=1 necessarily. 
		Hence, we obtain that
		
    Spec(Ψ')= Spec(Ψ).

		Therefore, Ψ=Ψ' as asserted.
	
	
	We are in position to give the following theorem, which says when the Lie algebra associated to two different polynomials (as in (<ref>)) are isomorphic.
	
		Let ϕ_1(x),ϕ_2(x) be polynomials over ℂ of degree greater or equal than 2.
		Let 𝔥_ϕ_1 and 𝔥_ϕ_2 be its associated solvable Lie algebras given as in Theorem <ref>.
		Then, 
		
    𝔥_ϕ_1≅𝔥_ϕ_2⟺ I_ϕ_1 = I_ϕ_2,

		where I_ϕ_1, I_ϕ_2 are as in (<ref>).
		Moreover, we have that
		
    𝔤_ϕ_1≅𝔤_ϕ_2⟺ I_ϕ_1 = I_ϕ_2,

		where 𝔤_ϕ_1 and 𝔤_ϕ_2 are the associated Lie algebras of ϕ_1 and ϕ_2, respectively.
	
	
		From Theorem <ref>, we have that 𝔤_ϕ_1≅𝔤_ϕ_2 if and only if 𝔥_ϕ_1≅𝔥_ϕ_2.
		So, it is enough to see that
		
    𝔥_ϕ_1≅𝔥_ϕ_2⟺ I_ϕ_1 = I_ϕ_2.

		Now by (<ref>), it enough to see that the associated matrices Φ_1 and Φ_2 are conformally similar. 
		By Theorem <ref> and (<ref>) we have that Φ_1 and Φ_2 are conformally similar to 
		
    Ψ = diag(1, j_1,…,j_k-2)   and  Ψ' = diag(1, j'_1,…,j'_k-2)   respectively,

		where  {j_1,…,j_k-2} =I_ϕ_1 and {j'_1,…,j'_k-2}=I_ϕ_2.
		Finally, by Lemma <ref>, we obtain that Ψ and Ψ' are conformally similar if and only if 
		Ψ=Ψ' which is equivalent to say that I_ϕ_1=I_ϕ_2. 
		Therefore 𝔥_ϕ_1≅𝔥_ϕ_2 if and only if I_ϕ_1= I_ϕ_2 as asserted.	
	
	
	As a direct consequence, we obtain the following.
	
		Let ϕ_1(x),ϕ_2(x) be polynomials over ℂ with degree greater than 2. 
		Then, we have the following cases:
		
			
  * If ϕ_1=ϕ_2=2, then 𝔤_ϕ_1≅𝔤_ϕ_2.
			
  * If ϕ_1≠ϕ_2, then 𝔤_ϕ_1≇𝔤_ϕ_2.
			
	
	
	
		Notice that if we consider ϕ_m(x)=x^m+ax with m≥ 2, then (𝔥_ϕ_m)=3. 
		The structure of solvable Lie algebras of dimension 3 
		was studied by J. Patera and H. Zassenhaus in <cit.>. 
		In page 4, the authors 
		define the Lie algebra 
		L_3,6=⟨ a_1,a_2,a_3⟩ with brackets
		
    [a_1,a_2]= a_3     [a_1,a_3]= a_3-α· a_2

		with parameter α satisfying α≠ 0 and 1-4α≠ 0,
		this parameter α is in one-to-one correspondence with isomorphism classes of this kind of algebras.
		Its associated matrix ψ_α(1) is 	
		
    ψ_α(1)=
    			[  0 -α;  1  1 ]

		The eigenvalues of ψ_α(1) are 
		
    λ_0=1-√(1-4α)2  and  λ_1=1+√(1-4α)2.

		On the other hand, if we consider ϕ_m(x)=x^m+ax with m≥ 2, 
		then 𝔥_ϕ_m has dimension 3 and
		its associated matrix Ψ_m is conformally similar to 
		
    [ 1 0; 0 m ]
 
		thus, Ψ_m is conformally similar to ψ_α(1) if and only if 
		
    λ_0=r,     λ_1=rm     for some complex number r,

		since diagonalizable matrices are similar if and only if its spectrum are equal. 
		This system of equation has a solution r=1m+1 and α= m(m+1)^2.
		Therefore 𝔥_ϕ_m≅ L_3,6^α with α=m(m+1)^2.
		
	
	
	

§ LAGUERRE TYPE SOLUTIONS

	Let A∈ M_N(ℂ) be a constant matrix and let ν∈ℝ such that ν>0. 
	In this section and the sequel, we are going to 
	consider the weight matrix  W given by
	
    W^(ν)(x) = e^Ax T^(ν)(x) e^A^∗ x,     T^(ν)(x) =  e^-x∑_k=1^N δ^(ν)_k x^ν+k  E_k,k.

	If we denote L(x)=e^Ax, then 
	
    W^(ν)(x)=L(x) T^(ν)(x) L^*(x).

	Recall that if A,J are as in (<ref>), the equation (<ref>) 
	in terms of L says that
	
    L(x)J L^-1(x)=J- Ax.

	In this case, we obtain the same kind of weight that was consider in section 3, with ϕ(x)=x.
	
	
		The first order differential operators
		
    𝒟 = ∂_x x + x(A-1),   𝒟^† = -∂_x x - (1+ν +J),

		are mutually adjoint and 
		satisfy
		
    M = ψ^-1(𝒟) =     (A-1)δ-(n+1+ν)-ℋ(n)Jℋ^-1(n),
    
    			M^† = ψ^-1(𝒟^†) =    -(n+ν+J+1) + ℋ(n)(A-1)^∗ℋ^-1(n-1) δ^-1.

	
	
		The operators 𝒟 and 𝒟^† are mutually adjoint by taking ϕ(x)=x in Proposition <ref>. 
		
		On the other hand, since v(x) has degree 1 in this case, by Corollary <ref> 
		we obtain that A_j(n)=0 for j≤ -1 and A_1(n)=A-1.
		
		Finally, the formula for A^†_0(n) can be obtained directly from the relation P·𝒟^†=M_𝒟^†· P 
		and the term A_0(n) can be obtained from equation (<ref>).
	
	
	As a direct consequence of the above proposition and  Corollary <ref> we obtain the following result.
	
		Let A,J∈ M_N(ℂ) as in (<ref>) and let W:=W^(ν)_ϕ be a matrix weight as in (<ref>) with ϕ(x)=x 
		and MVOPs P(x,n). 
		If X(n) and Y(n) are the coefficients of the (n-1)-term and (n-2)-term of P(x,n) respectively, then
		
    n+X(n)A - A X(n+1)-B(n) = -(n+1+ν)-ℋ(n)Jℋ^-1(n),

		
    X(n)+[J,X(n)]=ℋ(n)(A^∗-1) ℋ^-1(n-1),

		where ℋ(n) and B(n)are as in (<ref>) and (<ref>). 
	
	
		It follows from Proposition <ref> and Corollary <ref>, by taking into account the term A_0(n) of 𝒟.
		
		On the other hand, from the equality P·𝒟^†= M^†· P with
		
    𝒟^†= -∂_x x - (1+ν +J)   and    M^†=-(n+ν+J+1)+A^†_-1(n) δ^-1,

		we can obtained the equation (<ref>) from the above theorem. 
	
	
	

 §.§ Existence of the operator D

	Families of matrix valued orthogonal polynomials which are eigenfunctions of a second order differential operator are of great importance, see e.g. <cit.>, <cit.>, <cit.>, <cit.>.  Using the approach of <cit.>, we get a symmetric second-order differential operator which preserves polynomials and its degree. For this we establish a conjugation with a diagonal matrix differential operator. 
	
	Let us consider matrix valued polynomials F_2, F_1, F_0 of degrees two, one and zero respectively and let us assume that we have a matrix valued second-order differential operator D such that
	
    Q· D=(d^2Qdx^2)(x)   F_2(x) + (dQdx)(x)   F_1(x) +Q(x) F_0(x).

	for a matrix valued polynomial Q. It follows from the definition of the matrix valued inner product (<ref>) that a differential operator D is symmetric with respect to W if for all matrix valued polynomials G,H we have
	
    ∫_0^∞ (GD)(x)W(x)(H(x))^∗  dx = ∫_0^∞ G(x)W(x)((HD)(x))^∗ dx.

	By <cit.>, this symmetry condition is equivalent to the following equations
	
    F_2(x)W(x) = W(x) ( F_2(x))^∗,      
    		2 d(F_2W)dx(x) - F_1(x)W(x) = W(x) ( F_1(x))^∗, 
    d^2(F_2W)dx^2(x) - d(F_1W)dx(x) + F_0(x) W(x) = W(x) ( F_0(x))^∗,

	and	the boundary conditions 
	
    lim_x→ 0 F_2(x)W(x) = 0 = lim_x→∞ F_2(x)W(x), 
    lim_x→ 0 F_1(x)W(x) - d(F_2W)dx(x) = 0 = 
    		lim_x→∞ F_1(x)W(x) - d(F_2W)dx(x).

	
	We have the following lemma.
	
		The second order differential operator 
    D_Q=∂_x^2 x +∂_x ( 1+ν-x+J) -J
 
		is symmetric respect to the weight T^(ν)(x).
	
	
		By taking into account that F_2(x)=x, F_1(x)= 1+ν -x+J and F_0(x)=-J, it is a straightforward computation see that 
		(<ref>), (<ref>), (<ref>) and (<ref>) are satisfied for D_Q and T^(ν)(x).
	
	
	 
		The second order differential operator 
		
    D=∂_x^2 x +∂_x ( (A-1)x +1+ν+J) +Aν + JA -J
 
		is symmetric respect to the weight W(x). Moreover
		
    P· D = Γ· P   where  Γ(n)=A(n+ν+1+J)-n-J.

	
	
		It follows from Remark 4.1 in  <cit.>. 
	
	
	

 §.§ The Lie Algebra associated to W
 	
	Recall that a Lie algebra 𝔤 is called reductive if its radical is equal to its center. 
	
	
		Let A,J∈ M_N(ℂ) as in (<ref>) and 
		let us consider the operators
		
    𝒟 = ∂_x x + x(A-1),  𝒟^† = -∂_x x - (1+ν+J),   
    			D=∂_x^2 x +∂_x ( (A-1)x +1+ν+J) +Aν + JA -J.

		If x acts over matrix valued polynomials by right constant multiplication, 
		then we have that 
		
    [𝒟,x] = -x,     [𝒟^†,x]=x,     [𝒟,𝒟^†] = x,      [D,x]=-𝒟+𝒟^†,

		
    [𝒟,D]= -𝒟+ D - (1+ν),    [𝒟^†,D]= 𝒟^†- D+ (1+ν).

		The subjacent Lie algebra generated by {𝒟, 𝒟^†, D,x, I}	is isomorphic to the Lie algebra 𝒜=⟨ x_1,x_2,x_3,x_4,x_5⟩ with brackets
		
    [x_1,x_2]=-x_4,   [x_1,x_4]=-x_4 ,   [x_2,x_4]=x_4,    [x_3,x_4]=-x_1+x_2,

		
    [x_1,x_3]= -x_2+ x_3 +x_4 - (1+ν)x_5   and  [x_2,x_3]= x_1 - x_3 -x_4 + (1+ν)x_5,

		with correspondence:
		
    x_1⟼𝒟+x,   x_2⟼𝒟^†+x,    x_3⟼ D,   x_4⟼ x,    x_5 ⟼ 1.

	
	
		
		Let 𝒟'=𝒟+x and 𝒟'^†=𝒟^†+x.
		It can be shown by direct computation that
		
    [𝒟',x]=-x,    [𝒟'^†,x]= x,    [𝒟',𝒟'^†]=-x,    [D,x]=-𝒟'+𝒟'^†,

		
    [𝒟',D]= -𝒟'^†+ D +x - (1+ν),    [𝒟'^†,D]= 𝒟'- D -x + (1+ν).

		Clearly, the subjacent Lie algebra associated to this representation, is the Lie algebra 𝒜=⟨ x_1,x_2,x_3,x_4,x_5⟩ with brackets
		
    [x_1,x_2]=-x_4,   [x_1,x_4]=-x_4 ,   [x_2,x_4]=x_4,    [x_3,x_4]=-x_1+x_2,

		
    [x_1,x_3]= -x_2+ x_3 +x_4 - (1+ν)x_5   and  [x_2,x_3]= x_1 - x_3 -x_4 + (1+ν)x_5,

		with correspondence 
		
    x_1⟼𝒟+x,   x_2⟼𝒟^†+x,    x_3⟼ D,   x_4⟼ x,    x_5 ⟼ 1,

		as desired.		
	
	
	
	
	We have the following structure result.
	
	
		The Lie algebra 𝒜 defined as above is a 5-dimensional reductive algebra with center of dimension two, given by 𝒵_𝒜=⟨ x_1+x_2- x_4,x_5⟩. Moreover, 
		𝒜=[𝒜,𝒜]⊕𝒵_𝒜  with
		[𝒜,𝒜] isomorphic to SL(2,ℂ). In particular, 
		
    𝒞_1= -4x_4(x_1-x_3-x_4+(1+ν)x_5)+(x_4-x_1+x_2)^2,   𝒞_2= x_1+x_2- x_4  and  𝒞_3=x_5
 
		are Casimir elements of 𝒜.
	
	
		From Lie algebra theory (see <cit.>), the radical of 𝒜 can be computed from its Killing form, in this case we have that 
		
    Rad(𝒜)=𝒵_𝒜=⟨ x_1+x_2- x_4,x_5⟩,

		and so, the Lie algebra 𝒜 is reductive. 
		Now, from general theory, since 𝒜 is reductive, we obtain
		
    𝒜=[𝒜,𝒜] ⊕𝒵_𝒜.

		In this case, we obtain that
		
    [𝒜,𝒜]= ⟨  x_4,   x_1 -x_2,   x_1-x_3 -x_4 +(1+ν) x_5⟩.

		By taking a_1=x_4, a_2= x_1-x_2 and a_3=x_1-x_3-x_4+(1+ν)x_5 we obtain that 
		
    [a_1,a_2]=-2a_1,    [a_1,a_3]=a_1-a_2,    [a_2,a_3]=-a_3

		and so if we take â_2=a_1-a_2 and â_3=-a_3 we have 
		
    [a_1,â_2]=2a_1,    [a_1,â_3]=-â_2,    [â_2,â_3]=2â_3,

		and so [𝒜,𝒜] is isomorphic to SL(2,ℂ) by consider the map a_1↦ e_1 â_2 ↦ e_2 and â_3 ↦ e_3.
		In particular, the Casimir element of SL(2,ℂ) given by 4e_1e_3+e_2^2 induces a Casimir element of [𝒜,𝒜]
		
    𝒞_[𝒜,𝒜]= -4x_4(x_1-x_3-x_4+(1+ν)x_5)+(x_4-x_1+x_2)^2.

		By taking into account that 𝒞_[𝒜,𝒜] commutes with the central elements of 𝒜, we obtain that 𝒞_[𝒜,𝒜] commutes with all of the elements of  𝒜 and so is a Casimir element of 𝒜. 
		
		The last assertion is clear, since the central elements always are Casimir elements of a given Lie algebra.
	
	
	
	
		Notice that 
		
    𝒞=𝒞_2+ (1+ν )𝒞_3 = 𝒟+𝒟^†+x+(1+ν)
 
		it is also a Casimir invariant of 𝒜. 
		Hence, under the representation given by 𝒟,𝒟^†, D,x,1, 
		the image of this Casimir satisfies
		
    𝒞= Ax-J.

		Thus, in terms of M,M^† and L, we obtain that
		
    φ^-1(𝒞)=M+M^†+L+(1+ν).

		On the other hand, it can be check that
		
    𝒞_[𝒜,𝒜]=18(A^2x^2+ν^2+J^2+Ax-2ν Ax-2xJA+2ν J -1).

		Thus, 𝒞'=A^2x^2-2xJA+J+J^2 it is also a Casimir since
		
    𝒞'=8𝒞_[𝒜,𝒜]-(1-2ν)𝒞 - (ν^2-1)𝒞_3,

		moreover, notice that the relation [J,A]=A implies that
		𝒞'=𝒞^2-𝒞, and so we obtain that
		
    𝒞_[𝒜,𝒜]=18( 𝒞^2-2ν𝒞 + (ν^2-1)𝒞_3).

		Therefore, in this representation the Casimir element corresponding to 𝒞_[𝒜,𝒜] does not give more information than 𝒞.
		Hence, in the rest of the paper we will only consider the Casimir element 𝒞.
	
	
	We can also consider the Lie subalgebra generated by {x_1,x_2,x_4,x_5}. 
	Notice that a representation of this kind of algebra was consider in the above section by taking ϕ(x)=x.
	In this case, we have the following structure result.
	
	
	
		The Lie subalgebra 𝒜' = ⟨ x_1,x_2,x_4,x_5 ⟩ of 𝒜 is isomorphic to 𝔤_2⊕ℂ^2 where 𝔤_2 is the 2-dimensional solvable Lie algebra with bracket [e_1,e_2]=e_2.
		In particular, 𝒜' has no non-central Casimir invariants. 
	
	
	
		By taking the map 
		
    x_2↦ e_1,    x_4 ↦ e_2,    x_1+x_2-x_4↦ e_3   and    x_5 ↦ e_4.

		we obtain an isomorphic algebra of 𝒜', in this case the only non-vanishing bracket of ⟨ e_1,e_2,e_3,e_4⟩ is the bracket 
		[e_1,e_2]=e_2 and so 𝒜' is isomorphic to 𝔤_2⊕ℂ^2, as asserted. 
		
		The last assertion is a consequence of 𝔤_2 has not central elements.
		Hence, the only Casimir invariants of 𝒜' are the central elements. 
	
	
	In the sequel, in order to simplify the notation, we will consider 
	
    B_n:=B(n),   C_n:=C(n),   ℋ_n:=ℋ(n),   Γ_n= Γ(n).

	The following proposition is a consequence, of the relations between the brackets of M,M^†,L,Γ. 
	
	
		Let A,J∈ M_N(ℂ) be matrices as in (<ref>) and let B_n,C_n,ℋ_n and Γ_n be as in (<ref>). 
		Then,
		
    B_n (A-1) - (A-1) B_n+1 = 2 + ℋ_n+1 J ℋ_n+1^-1 - ℋ_n J ℋ_n^-1,

		
    B_n=[B_n,J] + ℋ_n (A^t-1) ℋ_n-1^-1 - ℋ_n+1 (A^t-1) ℋ_n^-1,

		
    2 ℋ_n ℋ_n-1^-1= [ℋ_n ℋ_n-1^-1,J] - B_n ℋ_n (A^t-1) ℋ_n-1^-1 - ℋ_n (A^t-1) ℋ_n-1^-1 B_n-1,

		
    B_n = -[J,ℋ_n J ℋ_n^-1] - ℋ_n (A^t-1) ℋ_n-1^-1 (A-1) + (A-1) ℋ_n+1 (A^t-1) ℋ_n^-1,

		
    [Γ, C_nδ^-1] = ℋ_n(A-1)^*ℋ_n-1^-1,

		
    [Γ_n,ℋ_nJ ℋ_n^-1]= n+Γ_n+ℋ_nJ ℋ_n^-1,

		
    [Γ,ℋ_n(A-1)^*ℋ_n-1^-1δ^-1]=-ℋ_n(A-1)^*ℋ_n-1^-1.

	
	
		The equation (<ref>) is consequence of seeing the coefficient of δ^1 in the bracket 
		relation [M,L]=L. 
		
		In the same way,  the equations (<ref>), (<ref>) are consequence of seeing the coefficients of δ^0 and δ^-1 in the bracket relation [M^†, L] = L.
		
		On the other hand, the equation (<ref>) it follows from the bracket relation [M,M^†] = L.
		The equation (<ref>) is a consequence of the coefficient of δ^-1 in the bracket [Γ,L] = -M+M^†.
		The equation (<ref>) is obtained from the coefficient of δ^0 in the bracket [Γ,M] = M-Γ+(1+ν).
		Finally, the equation (<ref>) can be obtained from the coefficient of δ^-1 in the bracket relation
		[Γ,M^†] = -M^†+Γ-(1+ν).
	
	
	 
		Let A,J∈ M_N(ℂ) be matrices as in (<ref>).
		Then,
		
    [B_n,J]    =  B_n  - Γ_nC_n + C_n Γ_n-1 + Γ_n+1 C_n+1 - C_n+1Γ_n, 
    
    			[C_n,J]   = 2C_n+B_n (Γ_nC_n - C_n Γ_n-1) + (Γ_nC_n - C_n Γ_n-1) B_n-1,

		where B_n,C_n,ℋ_n and Γ_n be as in (<ref>)
	
	
		By (<ref>) we have that 
		
    [B_n,J] = B_n - ℋ_n (A^t-1) ℋ_n-1^-1 + ℋ_n+1 (A^t-1) ℋ_n^-1.

		On the other hand, by (<ref>) and taking into account that ℋ_n∈ M_N(ℝ), we obtain that
		
    ℋ_n(A^t-1)ℋ_n-1^-1 =  [Γ, C_nδ^-1]   = Γ_nC_n - C_n Γ_n-1,
    ℋ_n+1(A^t-1)ℋ_n^-1 = [Γ, C_nδ^-1]   = Γ_n+1 C_n+1 - C_n+1Γ_n,

		and so we have that
		
    [B_n,J] =  B_n  - Γ_nC_n + C_n Γ_n-1 + Γ_n+1 C_n+1 - C_n+1Γ_n,

		as asserted.
		
		For the second equality, notice that since C_n=ℋ_nℋ_n-1^-1, 
		thus the equation (<ref>)  implies that 
		
    [C_n,J]=2C_n+B_n ℋ_n (A^t-1) ℋ_n-1^-1 + ℋ_n (A^t-1) ℋ_n-1^-1 B_n-1.

		In the same way as above, we obtain that
		
    [C_n,J]=2C_n+B_n (Γ_nC_n - C_n Γ_n-1) + (Γ_nC_n - C_n Γ_n-1) B_n-1,

		as desired.
	
	
	
	

§ MATRIX ENTRIES OF P(X,N) AS CLASSICAL LAGUERRE POLYNOMIALS

	
	In this section we will give explicit expressions of the entries of the Laguerre-type MVOPs in terms of the classical scalar Laguerre polynomials. For this we use the approach of <cit.>, <cit.>, <cit.>, which consists in observing that a symmetric second order differential operator can be diagonalized via conjugation with an appropriate matrix valued function. The present situation is more involved than the previous cases because, although the differential operator can be diagonalized, the eigenvalue remains non-diagonal.
	
	In the rest of the section, the weight matrix W(x) is as in the previous section.
	

 §.§ Step I: Diagonalizing the differential operator:
 
	Let A,J∈ M_N(ℂ) be matrices as in (<ref>). We can define the following auxiliary matrix valued polynomials
	
    Q(x,n):=P(x,n)L(x),     where L(x)= e^xA.

	The polynomials Q_n satisfy the following relations,
	
    Q_n·𝒟_Q = M · Q_n,     Q_n· D_Q = Λ_n · Q_n,     Q_n·𝒞_Q = M_𝒞· Q_n,

	where 
	
    𝒟_Q= L(x)^-1𝒟 L(x),      D_Q=L(x)^-1 D L(x),     𝒞_Q=L(x)^-1𝒞 L(x).

	Here 𝒟, D are as in Proposition <ref>, Proposition <ref> respectively and 𝒞=Ax-J . 
	In the following lemma, we show that 𝒟_Q, D_Q and 𝒞_Q are simple diagonal operators.
			
		The operators 𝒟_Q, D_Q and 𝒞_Q as in (<ref>)
		are given explicitly as follows: 
		
    𝒟_Q=  ∂_x x -x,      
    		D_Q=∂_x^2 x +∂_x ( 1+ν-x+J) -J,     𝒞_Q=-J.

	
	
	
		All of the equalities are follow directly from definition and the equation (<ref>).
	
	
	In the following proposition, we will use the expressions of 𝒞_Q, 𝒞 and 𝒟 
	in order to obtain an equation which relates Q(x,n) and the recurrent matrix H_n(A^∗-1)H_n-1^-1.
	
	
		The auxiliary functions Q(x,n)'s defined in (<ref>), 
		satisfy the following equation which depend on the squared norms:
		
    -Q(x,n)J=xQ'(x,n)- (n+J)Q(x,n)+ℋ(n)(A-1)^∗ℋ^-1(n-1)Q(x,n-1)   for n≥ 1

		and for n=0
		
    -Q(x,0)J=-J-xQ'(x,0).

	
	
		By Lemmas <ref> and <ref> we have that 	
		
    -Q(x,n)J = Q(x,n)·𝒞_Q = (M_𝒞· P(x,n))e^xA

		where M_𝒞 is the discrete operator
		
    M_𝒞=A δ + X(n)A-AX(n+1)-J + (Y(n)A-AY(n+1) + [J,X(n)] + (AX(n+1)-X(n)A)X(n))δ^-1.
		
		By equation (<ref>), we have
		
    (n-1)X(n)+Y(n)(A-1)-(A-1)Y(n+1)-( n+X(n)A - A X(n+1)-B(n))X(n) = 0,
 
		and so 
		
    Y(n)A-AY(n+1)  + (AX(n+1)-X(n)A)X(n)= X(n)+Y(n)-Y(n+1)-B(n)X(n).

		By taking into account the relation P· x =L· P with L=δ+B(n)+C(n)δ^-1, 
		thus we have that
		
    Y(n)=Y(n+1)+B(n)X(n)+C(n).

		Hence, we obtain that
		
    (M_𝒞· P(x,n))e^xA= AQ(x,n+1) + (X(n)A-AX(n+1)-J)Q(x,n)+ (C(n) + [J,X(n)] + X(n))Q(x,n-1).

		On the other hand, by Corollary <ref> we have that
		
    (M_𝒟· P(x,n))e^xA   =    (A-1) Q(x,n+1)+ (n+X(n)A - A X(n+1)-B(n))Q(x,n), 
    
    				(L · P(x,n))e^xA   =    Q(x,n+1) + B(n)Q(x,n)+ C(n) Q(x,n-1),

		where B(n) and C(n) are as in equation (<ref>). Hence, we have that
		
    ((M_𝒟+L)· P(x,n))e^xA= A Q(x,n+1)+(n+X(n)A - A X(n+1))Q(x,n)+C(n)Q(x,n-1)

		and thus
		
    (M_𝒞· P(x,n))e^xA= ((M_𝒟+L)· P(x,n))e^xA-(n+J)Q(x,n)+ (X(n)+[J,X(n)])Q(x,n-1).

		Notice that if we denote L(x)=e^xA, the Lemma <ref> implies that
		
    ((M_𝒟+L)· P(x,n))L(x)=(P(x,n)·(𝒟+x))L(x)= Q(x,n)· L^-1(x)(𝒟+x))L(x)= Q(x,n)·∂_xx,

		and by (<ref>), X(n)+[J,X(n)]=ℋ(n)(A-1)^∗ℋ^-1(n-1). 
		Thus, we obtain that
		
    -Q(x,n)J= xQ'(x,n)- (n+J)Q(x,n)+ℋ(n)(A-1)^∗ℋ^-1(n-1),

		as asserted.
		Finally, the equation for n=0, it follows from equation (<ref>).
	
	
	
	
	

 §.§ Step II: Diagonalizing the eigenvalue Λ_n:
 
	Although the differential operator D_Q is a diagonal operator, the system of equations given by Q_n· D_Q = Λ_n Q_n is not a decoupled system since Λ_n is a lower triangular matrix. However, Λ_n can be diagonalized in a somewhat simple way:
	
    Γ_n=A(n+ν+J+1) - (n+J) = K_n Λ_n K_n^-1,

	where Λ_n is the diagonal matrix Λ_n = -(n+J).   
	
		We can choose K_n such that is a lower triangular matrix with diagonal elements (K_n)_i,i=1 for all i=1,…,N. 
		Moreover, in this case K_n is the following matrix: 
		
    (K_n)_i,j=
    			
    				(-1)^i-j(n+ν + j+1)_i-1(i-j)!∏_k=j^i-1a_k      i> j, 
    
    				1     i=j, 
    
    				0     i<j.

	
	
		Since A(n+ν+J+1) - (n+J) is lower triangular, the its characteristic polynomial satisfy 
		
    (λ I -(A(n+ν+J+1) - (n+J)))=(λ I +nI+J)=∏_r=1^N(λ+n+r).

		Then, the eingevalues of A(n+ν+J+1) - (n+J) are 
		
    λ_1=-(n+1), …, λ_N=-(n+N)   with multiplicity 1.

		Since K_n diagonalizes A(n+ν+J+1) - (n+J), 
		then its r-th column can be obtained from the eigenspace correspond 
		to λ_r=-(n+r), that is
		
    Nu(λ_r I-A(n+ν+J+1) + n+J)=Nu(-A(n+ν+J+1) +J-rI),    for r=1, …,N.

		We can obtain (<ref>) by a straightforward computation of these eigenspaces. 
	
	With the matrix K_n as in (<ref>), we will consider the following matrix polynomial 
	
    R(x,n):=K_n^-1Q(x,n).

	The following result that shows a relationship between the non-zero matrix entries of R(x,n) and generalized Laguerre polynomials.
	
	
		Let n∈ℕ and let ν>0.
		The matrix elements of R(x,n) are multiples of scalar Laguerre functions 
		
    R(x,n)_i,j= 
    			
    				L^(ν + j)_n+i-j(x) ξ(n,i,j)    if n+i-j ≥ 0
    
    				0    if n+i-j < 0.

	
	
		Notice that the polynomials  R(x,n)'s are eigenfunctions of  D_Q=∂_x^2 x + ∂_x ( 1+ν-x+J) -J 
		with associated eigenvalues Λ_n=-(n+J) where J is the diagonal matrix diag(1,2,…,N). 
		If we look the (i,j)-entry of
		
    xR”(x,n) + R'(x,n) (1+ν-x+J) + (nR(x,n) + JR(x,n) -R(x,n)J)=0,

		we obtain that the following expression
		
    xR”(x,n)_i,j + ∑_k=1^N R'(x,n)_i,k (1+ν-x+J)_k,j + nR(x,n)_i,j + ∑_k=1^N (J_i,kR(x,n)_k,j - R(x,n)_i,kJ_k,j) = 0.

		Since J=diag(1,2,…,N), the above equality is equivalent to
		
    xR”(x,n)_i,j +  R'(x,n)_i,j (1+ν-x+j) + (n+i-j)R(x,n)_i,j = 0.

		Hence, we obtain that 
		
    R(x,n)_i,j= L^(ν+j)_n+i-j(x) ξ(n,i,j),

		as asserted.
		
		On the other hand,  it is well-known that if M<0 the only solution for the differential equation 
		
    x P”(x) +  P'(x) (1+ν-x) + M P(x) = 0,

		is P(x)=0 and since
		
    xR”(x,n)_i,j +  R'(x,n)_i,j (1+ν-x+j) + (n+i-j)R(x,n)_i,j = 0,

		we obtain that R(x,n)_i,j=0 if n+i-j<0, as asserted.
	
	
	
		Notice that by the above theorem the are only defined for n+i-j ≥ 0, so we extend its definition as follows
		
    ξ(n,i,j)=0     if n+i-j < 0.

	
	
	It is well-known that the generalized Laguerre polynomial satisifes
	
    L^(α)_N(0)=(α+1)_N/N!,

	where (a)_N is the Pochhammer symbol defined by
	
    (a)_N= 
    		
    			1    if N=0,
    
    			a(a+1)⋯(a+N-1)    if N>0.

	As a direct consequence of the above theorem we obtain the following corollary.
	
		Let n∈ℕ and let ν>0.
		Then, the coefficients of R(0,n) satisfy
		
    R(0,n)_i,j= 
    			(ν+j+1)_n+i-j/(n+i-j)!ξ(n,i,j)    if n+i-j ≥ 0,
    
    				0    if n+i-j < 0.

		In particular, the (i,n+i)-th and (i,n+i-1)-th coordinates of R(0,n) satisfy 
    R(0,n)_i,n+i=ξ(n,i,n+i)   and   R(0,n)_i,n+i-1=(n+ν+i)ξ(n,i,n+i-1).

	
	Now we need to identify the coefficients ξ(n,i,j). 
	For this, we exploit the relation in Proposition <ref>. In the following lemma, we observe that the factor ℋ(n)(A-1)^∗ℋ^-1(n-1) in this relation is turned into a diagonal matrix via multiplication by appropriate matrices K_n. This will allow us to obtain a simple recursion for ξ(n,i,j). For this purpose, we define the following 
	
    G(n):= K_n^-1ℋ_n (A^∗-1)ℋ_n-1^-1K_n-1     I(n):= K_n^-1ℋ_n J ℋ_n^-1K_n,
	
	where ℋ_n and K_n are as in (<ref>) and (<ref>), respectively. 
	
		For n≥ 1 and let  G(n), I(n) be the matrices as in (<ref>).
		Then, G(n) is diagonal and I(n) satisfies
		
    (I(n))_i,i = i,      (I(n))_i,j=0   for  i≠ j  and  i ≠ j-1.

		Moreover
		
    (G(n))_i,i= (ℋ_n (A^∗-1)ℋ_n-1^-1)_i,i  and   (I(n))_i,i+1=(ℋ_n J ℋ_n^-1)_i,i+1.

	
	
	
		By equation (<ref>), 
    [Γ_n,ℋ_n(A^∗-1)ℋ_n-1^-1δ^-1]=-ℋ_n(A^∗-1)ℋ_n-1^-1.

		Then, 
		
    K_n^-1Γ_n(ℋ_n(A^∗-1)ℋ_n-1^-1)K_n-1-K_n^-1(ℋ_n(A^∗-1)ℋ_n-1^-1)Γ_n-1K_n-1=-G(n).

		Then, by K_n^-1Γ_nK_n=Λ_n=-(n+J) we obtain that
		
    Λ_n G(n)-G(n) Λ_n-1=-G(n).

		The assertion it follows by observing the (i,j)-entry for i≠ j.
		On the other hand, from definition we have that
		
    K_n G(n) K_n-1^-1=  ℋ_n (A^∗-1)ℋ_n-1^-1.

		Since K_n and K_n-1^-1 are both lower triangular matrices with 1's in its diagonal, then the left term in the above equation is a lower triangular matrix with (i,i)-th coordinate equal to (G(n))_i,i and so
		
    (ℋ_n (A^∗-1)ℋ_n-1^-1)_i,i=(K_n G(n) K_n-1^-1)_i,i=(G(n))_i,i,

		as asserted.
		
		Now, for the second assertion, we can proceed as in the same way, 
		in this case by equation (<ref>), we have that 
		
    [Γ_n,ℋ_nJ ℋ_n^-1]=n+Γ_n + ℋ_nJℋ_n^-1.

		Then, we obtain that
		
    K_n^-1Γ_n ℋ_nJ ℋ_n^-1K_n-K_n^-1ℋ_nJ ℋ_n^-1Γ_n K_n = K_n^-1(n+Γ_n+ℋ_nJ ℋ_n^-1)K_n.

		Hence, by K_n^-1Γ_nK_n=Λ_n=-(n+J) we obtain that
		
    Λ_n I(n)-I(n) Λ_n = n+ Λ_n + I(n)).

		The proof follows by observing the (i,j)-entry in the above matrix equality.
		Finally, from definition we have 
		
    K_nI(n)K_n^-1=ℋ_n J ℋ_n^-1.

		So, in general we have that 
		
    (K_nI(n)K_n^-1)_i,j= ∑_k=1^N (K_n)_i,k (I(n)K_n^-1)_k,j  and   (I(n)K_n^-1)_k,j=(I(n))_k,k(K_n^-1)_k,j+(I(n))_k,k+1(K_n^-1)_k+1,j.

		By taking into account that (K_n)_i,j=(K_n^-1)_i,j=0 for j>i, 
		if j=i+1 we obtain that
		
    (K_nI(n)K_n^-1)_i,i+1=∑_k=1^N (K_n)_i,k (I(n)K_n^-1)_k,j=∑_k=1^i (K_n)_i,k (I(n)K_n^-1)_k,i+1= (I(n))_i,i+1(K_n^-1)_i+1,i+1,

		by taking into account that (K_n^-1)_i+1,i+1=1 for any i. Therefore, we have that (K_nI(n)K_n^-1)_i,i+1=(I(n))_i,i+1, as desired.
	
	
	
	The following proposition is a consequence of the relation given by the Casimir operator and Proposition 6.4
	
	
		Let ξ(n,i,j) as in Theorem <ref>.  
		If n+i-j> 0, then the constants ξ(n,i,j)'s satisfy the following: 
		
			
  * ξ(0,i,j)=(K_0^-1)_i,j(i-j)!(ν+j+1)_i-j,
			
  * If i=1 and n>0 then 
			
    ξ(n,1,j) =(G(n))_1,1 n+ν+1ξ(n-1,1,j),

			
  * If i>1 and n>0, then 
			
    ξ(n,i,j) = a_i-1ξ(n,i-1,j) +(G(n))_i,i n+ν+iξ(n-1,i,j),

			
		with G(n) as in (<ref>).
	
	
		For the first assertion, recall that 
		
    R(0,0)=K_0^-1Q(0,0)=K_0^-1P(0,0)=K_0^-1,
 
		thus we have that  
		
    (K_0^-1)_i,j=ξ(0,i,j)L^(ν+j)_i-j(0).

		By taking into account that L^(ν)_N(0)=(ν+1)_NN! for any N, hence we obtain 
		
    (K_0^-1)_i,j(i-j)!(ν+j+1)_i-j=ξ(0,i,j),

		as asserted.
		
		For items (b) and (c), recall that Proposition <ref> implies that 
		
    -Q(0,n)J = -(n+J)Q(0,n) + ℋ(n) (A^∗-1) ℋ(n-1)^-1 Q(0,n-1).

		Then,
		
    -K_n R(0,n)J = -(n+J)K_n R(0,n) + ℋ(n) (A^∗-1) ℋ(n-1)^-1 K_n-1R(0,n-1),

		and so we obtain that
		
    -R(0,n)J = -K_n^-1(n+J)K_n R(0,n) +G(n) R(0,n-1)

		where G(n)=K_n^-1ℋ(n) (A^∗-1) ℋ(n-1)^-1 K_n-1.
		By recalling that 
		
    K_n^-1(n+J)K_n R(0,n)=(n+J)-A(n+ν+J+1),

		we obtain that 
		
    -R(0,n)J = -(n+J) R(0,n)+ A(n+ν+J+1) R(0,n)+ G(n)R(0,n-1).

		Thus, in terms of coordinates we have that
		
    -j R(0,n)_i,j = -(n+i)R(0,n)_i,j + ∑_k=1^N(A(n+ν + J+1))_i,kR(0,n)_k,j +  ∑_k=1^N (G(n))_i,kR(0,n-1)_k,j.

		
		Since A has only non-zero entries a_i's in the place (i,i+1) and n+ν + J+1 is diagonal, we obtain that
		
    ∑_k=1^N(A(n+ν + J+1))_i,kR(0,n)_k,j=
    			
    				(a_i-1(n+ν + i))R(0,n)_i-1,j   if i>1, 
    
    				0    if i=1.
	
		Thus, for i>1 the equation (<ref>) takes the form	
		 
    -j R(0,n)_i,j=  -(n+i)R(0,n)_i,j + a_i-1(n+ν + i)R(0,n)_i-1,j+  (G(n))_i,iR(0,n-1)_i,j
 
		where in the last term of the equality, we use Lemma <ref>. 
		By Theorem <ref>, we have that
		
    (n+i-j) L^(ν+j)_n+i-j(0) ξ(n,i,j) = L^(ν+j)_n+i-1-j(0) (a_i-1(n+ν+i)   ξ(n,i-1,j)+ (G(n))_i,iξ(n-1,i,j)).

		Therefore, since n+i-j>0 we obtain a similar expression of (<ref>) by multiplication for ((n+i-j) L^(ν+j)_n+i-j(0))^-1, that is
		
    ξ(n,i,j) = C_1(n,i,j)ξ(n,i-1,j) +C_2(n,i,j) ξ(n-1,i,j),

		where
		
    C_1(n,i,j) = (a_i-1(n+ν+i))  L^(ν+j)_n+i-1-j(0)(n+i-j) L^(ν+j)_n+i-j(0)  and   C_2(n,i,j) = (G(n))_i,i L^(ν+j)_n-1+i-j(0)(n+i-j) L^(ν+j)_n+i-j(0).

		To finish the proof, recall that
		
    L^(α)_N(0)=(α+1)_N/N!,

		where (a)_N is the Pochhammer symbol defined by
		
    (a)_N= 
    		
    			1    if N=0,
    
    			a(a+1)⋯(a+N-1)    if N>0.

		Hence, we have that 
		
    L^(ν+j)_n+i-1-j(0)/L^(ν+j)_n+i-j(0)= n+i-j/n+ν+i.

		Therefore we obtain (<ref>), as asserted.
		
		Now, for  i=1 the equation (<ref>) takes the form
		
    -j R(0,n)_1,j = -(n+1)R(0,n)_i,j + (G(n))_1,1R(0,n-1)_1,j.

		So, the equation (<ref>) it can be prooved in a similar way as in the case i>1. 
	
	
		Notice that the item (a) in the above proposition still holds for n+i-j=0 since in this case we just use the definition of ξ's.
	
	
	Now, we are going to study the case n+i-j=0. 
	In this case, we have the following result.
	
	
		Let n∈ℕ_0 and let I(n),  G(n) be as in (<ref>). 
		If i≥1, then the constants ξ's satisfy the following:
		
			
  * ξ(0,i,i)= 1 and ξ(1,i,i+1)= I(0)_i,i+1.
			
  * If i=1 and n>0, then 
			
    N_1(n,i) ξ(n,1,n+1)= N_2(n,i) ξ(n-1,2,n+1),    with
 
			
    N_1(n,i)=(ν+2n+3) (G(n+1))_1,1 n+ν+2 + (n+2+ν) + I(n)_1,2 (ν+2n+2) a_1,    N_2(n,i)=I(n)_1,2 (ν+2n+2)(G(n))_2,2 n+ν+2.

			
  * If i>1 and n>0, then 
			
    M_1(n,i)ξ(n+1,i-1,n+i)= M_2(n,i)ξ(n,i,n+i)+M_3(n,i)ξ(n-1,i+1,n+i),

			
    with    M_1(n,i)=a_i-1( i(n+1+ν+i)_i-2-(n+ν+i)),
 
			
    M_2(n,i)=(G(n+1))_i,i + (n+ν+i+1),     M_3(n,i)=(I(n))_i,i+1 G(n)_i+1,i+1.

		
	
	
	
		The first assertion of item (a) it follows from item (a) of <ref> (see Remark <ref>). Indeed, since K_n^-1 has a diagonal of 1's, in this case we have that
		
    ξ(0,i,i)= (K_0^-1)_i,i0!(ν+i+1)_0=(K_0^-1)_i,i=1.
 
		
		By Proposition <ref>, we have
		𝒟 = ∂_x x + x(A-1) and M = (A-1)δ-(n+1+ν)-ℋ(n)Jℋ^-1(n) satisfies 
		
    P_n ·𝒟 = M · P_n.

		By recalling that (P_n ·𝒟)(0)=0, 
		we obtain that 
		
    (A-1)P(0,n+1)-(n+1+ν)P(0,n)-ℋ_nJℋ^-1_n P(0,n)=0,
 
		since P(0,m)=K_m R(0,m), we have that
		
    K_n^-1(A-1)K_n+1 R(0,n+1)-(n+1+ν)R(0,n)-I(n) R(0,n)=0

		where I(n)=K_n^-1ℋ_n Jℋ_n ^-1K_n. 
		
		If we consider the expression (<ref>) with n=0, we arrive to
		
    0 = K_0^-1(A-1)K_1 R(0,1)-K_0^-1(1+ν)K_0 R(0,0)-I(0) R(0,0).

		By taking the (i,i+1)-th coordinate, we obtain that
		
    0 = - R(0,1)_i,i+1-(1+ν)R(0,0)_i,i+1-I(0)_i,i R(0,0)_i,i+1- I(0)_i,i+1R(0,0)_i+1,i+1.

		From Theorem <ref> we have 
		
    ξ(1,i,i+1)= I(0)_i,i+1ξ(0,i+1,i+1)=I(0)_i,i+1.

		as asserted.
		
		Now, let us consider n>0 in the equation (<ref>). 
		By taking into account the (i,n+i)-coordinate in (<ref>),
		
		
    ∑_r=1^N(K_n^-1(A-1)K_n+1)_i,rR(0,n+1)_r,n+i-(n+1+ν) R(0,n)_i,n+i-∑_r=1^NI(n)_i,rR(0,n)_r,n+i=0.
 
		By Lemma (<ref>) and since R(0,n+1)_r,n+i= 0 for r<i-1 we have that 
		
    ∑_r=i-1^N(K_n^-1(A-1)K_n+1)_i,rR(0,n+1)_r,n+i-(n+1+ν+i) R(0,n)_i,n+i-I(n)_i,i+1R(0,n)_i+1,n+i=0.
 
		
		On the other hand, since the matrix K_n^-1(A-1)K_n+1 is lower triangular we obtain that
		
    ∑_r=i-1^N(K_n^-1(A-1)K_n+1)_i,rR(0,n+1)_r,n+i= ∑_r=i-1^i(K_n^-1(A-1)K_n+1)_i,rR(0,n+1)_r,n+i.
 
		By taking into account that
		(K_n^-1(A-1)K_n+1)_i,i-1= a_i-1 -(K_n^-1K_n+1)_i,i-1 and  (K_n^-1(A-1)K_n+1)_i,i=-1,
		we obtain that
		
    0    =   (a_i-1 -(K_n^-1K_n+1)_i,i-1) R(0,n+1)_i-1,n+i- R(0,n+1)_i,n+i
       -   (n+1+ν+i)R(0,n)_i,n+i-I(n)_i,i+1R(0,n)_i+1,n+i.

		By Corollary <ref> we have
		
    0    =   (a_i-1 -(K_n^-1K_n+1)_i,i-1) ξ(n+1,i-1,n+i) - (n+1+ν+i) ξ(n+1,i,n+i) 
       -   (n+1+ν+i) ξ(n,i,n+i) -I(n)_i,i+1 (n+ν +i+1)ξ(n,i+1,n+i).

		
		On the other hand, by Proposition <ref> if n+i-j>0 we know that 
		
    ξ(n,i,j) = a_i-1ξ(n,i-1,j) +(G(n))_i,i n+ν+iξ(n-1,i,j).

		Thus, in particular we obtain 
		
    ξ(n+1,i,n+i) = a_i-1ξ(n+1,i-1,n+i) +(G(n+1))_i,i n+1+ν+iξ(n,i,n+i),

		
    ξ(n,i+1,n+i) = a_iξ(n,i,n+i) + (G(n))_i+1,i+1)n+ν+i+1) ξ(n-1,i+1,n+i)

		and so we have 
		
    (a_i-1 -(K_n^-1K_n+1)_i,i-1) ξ(n+1,i-1,n+i)
          - (ν+n+i+1) (a_i-1ξ(n+1,i-1,n+i) +(G(n+1))_i,i n+1+ν+iξ(n,i,n+i))
          = (n+1+ν+i) ξ(n,i,n+i) 
          + I(n)_i,i+1 (n+1+ν+i)( a_iξ(n,i,n+i) + (G(n))_i+1,i+1n+ν+i+1ξ(n-1,i+1,n+i)).

		Hence 
		
		
    M_1(n,i)ξ(n+1,i-1,n+i)= M_2(n,i)ξ(n,i,n+i)+M_3(n,i)ξ(n-1,i+1,n+i),

		with M_1(n,i)=-(K_n^-1K_n+1)_i,i-1 - a_i-1(ν+n+i),  M_2(n,i)=(G(n+1))_i,i + (n+ν+i+1), and M_3(n,i)=(I(n))_i,i+1 G(n)_i+1,i+1.
		To finish the proof, notice that since K_n^-1 and K_n+1 are both lower triangular matrix with 1's in the diagonal, we have that
		
    (K_n^-1K_n+1)_i,i-1=(K_n^-1)_i,i-1+(K_n+1)_i,i-1  and   (K_n^-1)_i,i-1=-(K_n)_i,i-1,

		by definition of K_n's we have that
		
    (K_n^-1K_n+1)_i,i-1=a_i-1( (n+ν+i)_i-1-(n+1+ν+i)_i-1)=-a_i-1 i(n+1+ν+i)_i-2.

		Hence, 
    M_1(n,i)=a_i-1( i(n+1+ν+i)_i-2-(n+ν+i)),

		as asserted.
		
		For the case i=1, j=n+1 in the expression (<ref>) we obtain
		
    0 = - R(0,n+1)_1,n+1-(n+2+ν) R(0,n)_1,n+1-I(n)_1,2R(0,n)_2,n+1,
 
		then, from Corollary <ref> we have
		
    0 = - (ν+2n+3)ξ(n+1,1,n+1)-(n+2+ν) ξ(n,1,n+1)-I(n)_1,2 (ν+2n+2) ξ(n,2,n+1).
 
		As a consequence of Proposition <ref>	we have that	 
		
    ξ(n,i,j) = a_i-1ξ(n,i-1,j) +(G(n))_i,i n+ν+iξ(n-1,i,j)   for j<n+i,

		which implies that	
		
    ξ(n,2,n+1) = a_1ξ(n,1,n+1) +(G(n))_2,2 n+ν+2ξ(n-1,2,n+1),

		and 
		
    ξ(n,1,j) =(G(n))_1,1 n+ν+1ξ(n-1,1,j)   for j<n+1.
 
		In particular    
    ξ(n+1,1,n+1)=(G(n+1))_1,1 n+ν+2ξ(n,1,n+1).
 
		Thus, we obtain     
		
    N_1(n,i) ξ(n,1,n+1)= N_2(n,i) ξ(n-1,2,n+1),

		with 
		
    N_1(n,i)=	(ν+2n+3) (G(n+1))_1,1 n+ν+2 + (n+2+ν) + I(n)_1,2 (ν+2n+2) a_1,    N_2(n,i)=I(n)_1,2 (ν+2n+2)(G(n))_2,2 n+ν+2

		
		as desired.     
	
	
	
	As a consequence of Propositions <ref> and	<ref> we obtain the following result.
	
		Let n≥ 0 and let G(n),I(n) as in (<ref>). 
		Then, all of the non-zero entries of R(x,n) can be found in terms of G(ℓ) and I(ℓ)  and the generalized Laguerre polynomials 
		L^(α)_ℓ for ℓ=0,…,n.
	 
	
		The equality (<ref>) implies that
		(R(x,n))_i,j=L^(ν+j)_n+i-j(x)ξ(n,i,j) for n+i-j≥ 0. 
		It is enough to show that all of the non-zero constants ξ(n,i,j) can be obtained in terms of G(ℓ) and I(ℓ) for ℓ=0,…,n+1.
		
		By items (a)'s of Propositions <ref> and <ref> we obtain the values of ξ(0,i,j). 
		Thus, assume that n>0 and suppose that we want to determine ξ(n,i,j) with n+i-j>0. 
		Notice that each time that we use items (b) and (c) of Proposition <ref>, 
		the value of "n+i-j" it reduces by 1, so if we use these items inductively we obtain that 
		ξ(n,i,j) can be determined by the values of somes ξ(n',i',j')'s with n'+i'-j'=0  and in each step also appear G(ℓ) with ℓ=0,…,n.
		So, it is enough to see that we can determine ξ(n,i,j) with n+i-j=0, in terms of G(ℓ) and  I(ℓ).
	
	
	 
		Notice that by Lemma <ref> and Propositions <ref>, <ref>, 
		we can replace (G(n))_i,i and (I(n))_i,i+1 by the expressions (ℋ_n(A^∗-1)ℋ_n-1^-1))_i,i and (ℋ_n J ℋ_n^-1)_i,i+1, respectively.
	
	
	As a direct consequence of the above results and the equations obtained in Proposition <ref>, 
	we obtain a three-terms non-linear recursion for ℋ_n. With this in mind, we need the following lemma.
	
	
		Let A,J∈ M_N(ℂ) be matrices as in (<ref>).
		Then, the matrix ℋ_1 can be obtained from ℋ_0.
	
	
		By (<ref>), we have that
		
    ℋ_1=(X(1)+[J,X(1)])ℋ_0 (A^*-1)^-1.

		So, it is enough to show that we can obtain X(1) in terms of ℋ_0.
		
		In order to show this, recall that P(x,1)=x+ X(1). 
		Let us put P_1(x):=P(x,1), by applying the operator D=∂_x^2 x +∂_x ( (A-1)x +1+ν+J) +Aν + JA -J to P_1(x), we have that
		
    (P_1· D)(x)=  (A-1)x +1+ν+J + (x+X(1))(Aν + JA -J),

		by taking into account that P_1· D= Γ_1 · P_1, where Γ_1 is the discrete constant operator A(ν+2+J)-1-J. 
		So we obtain that
		
    (A-1)x +1+ν+J + (x+X(1))(Aν + JA -J)= (A(ν+2+J)-1-J)(x+X(1)).

		After some computation, we obtain that
		
    X(1)(Aν + JA -J) +1+ν+J = (A(ν+2+J)-1-J)X(1),

		by taking into account that [J,A]=A, we obtain that JA=A+AJ and hence
		
    [X(1),A(1+ν+J) ] +X(1)+[J,X(1)] + 1+ν+J -AX(1)=0.

		Thus, by seeing the (i,j)-th coordinate in the above equality we obtain the following recurrences
		
    a_j(ν+j+1) X(1)_1,j+1+ (2-j) X(1)_1,j+ (1+ν+J)_1,j=0,

		
    a_j(ν+j+1) X(1)_i,j+1- a_i-1(ν+i+1)X(1)_i-1,j + (1+i-j) X(1)_i,j+ (1+ν+J)_i,j=0   for i≥ 2.

		
		Recall that by Theorem <ref> we have that 
		(R(0,1))_i,j=0 if i+1< j.
		
		Claim:  If i+1<j then X(1)_i,j=0.
		
		We are going to prove this assertion by induction on i.
		Assume first that i=1 and let us consider  j>2,  in this case
		
    0=(R(0,1))_1,j= (K_1 P(0,1))_1,j=∑_r=1^N(K_1)_1,r X(1)_r,j=X(1)_1,j.

		
		Now, let i>1 and assume that the statement is true for r<i, that is X(1)_r,j=0 when r+1<j. 
		Thus, if i+1<j then
		
    0=(R(0,1))_i,j= (K_1 P(0,1))_i,j=∑_r=1^N(K_1)_i,r X(1)_r,j= (K_1)_i,iX(1)_i,j=X(1)_i,j.

		By induction hypothesis and by taking into account that K_1 is a lower triangular matrix with 1's  in its diagonal, 
		we have that 
		
    ∑_r=1^N(K_1)_i,r X(1)_r,j=∑_r=1^i(K_1)_i,r X(1)_r,j= (K_1)_i,iX(1)_i,j=X(1)_i,j.

		Therefore, X(1)_i,j=0 when i+1<j as claimed.
		
		Hence, by equations (<ref>) and (<ref>), we can observe by a recursive argument, that in order to compute X(1), 
		it is enough to know the value of X(1)_i,i+1 for any i≥ 1.
		By taking into account that 
		
    (R(0,1))_i,i+1=(K_1 P(0,1))_i,i+1=∑_r=1^i(K_1)_i,r (X(1))_r,i+1=X(1)_i,i+1,

		thus by Corollary <ref>, we obtain that
		
    X(1)_i,i+1=(R(0,1))_i,i+1=ξ(1,i,i+1).

		Thus, by item (a) of Proposition <ref>, we obtain that 
		
    X(1)_i,i+1=ξ(1,i,i+1)=I(0)_i,i+1= (ℋ_0 J ℋ_0^-1)_i,i+1.

	
	
	
		Let A,J∈ M_N(ℂ) be matrices as in (<ref>).
		Then,
		
    ℋ_n+2 = (A-1)^-2( (-[J,ℋ_n J ℋ_n^-1] - ℋ_n (A^t-1) ℋ_n-1^-1 (A-1) + (A-1) ℋ_n+1 (A^t-1) ℋ_n^-1)(A-1) 
    
    				-2-ℋ_n+1 J ℋ_n+1^-1 + ℋ_n J ℋ_n^-1 +(A-1)[J,ℋ_n+1 J ℋ_n+1^-1]+(A-1)ℋ_n+1(A^t-1)ℋ_n^-1(A-1) )ℋ_n+1 (A^t-1)^-1,

		where B_n,C_n and ℋ_n be as in (<ref>). 
		
		Moreover,
		
    (ℋ_0)_i,j = Γ(ν) ∑_r=1^min{i,j}δ_r^(ν)/(i-r)!(j-r)!(∏_k=r^i-1 a_k ) (∏_s=r^j-1 a_s) (ν)_i+j-r,

		where Γ is the Gamma function.
	
	
		By (<ref>), we have that
		
    B_n+1 =(A-1)^-1(B_n (A-1) - 2 - ℋ_n+1 J ℋ_n+1^-1 + ℋ_n J ℋ_n^-1).

		On the other hand, the equation (<ref>) implies
		
    B_n = -[J,ℋ_n J ℋ_n^-1] - ℋ_n (A^t-1) ℋ_n-1^-1 (A-1) + (A-1) ℋ_n+1 (A^t-1) ℋ_n^-1.

		
    B_n+1 = -[J,ℋ_n+1 J ℋ_n+1^-1] - ℋ_n+1 (A^t-1) ℋ_n^-1 (A-1) + (A-1) ℋ_n+2 (A^t-1) ℋ_n+1^-1

		The statement it follows by changing B_n+1, and B_n in (<ref>).
		
		For the last assertion, by definition we have that
		
    ℋ_0= ∫_0^∞ e^xA T^(ν)(x)e^xA^∗ dx     with    T^(ν)(x)=e^-x∑_k=1^Nδ_k^(ν)x^ν+kE_k,k.
 
		Then,
		
    (ℋ_0)_i,j = ∑_r=1^Nδ_r^(ν)∫_0^∞ e^-x x^(ν+r) (e^xA)_i,r (e^xA^∗)_r,j.

		By taking into account that A^∗_r,j=A_j,r, and (e^xA)_i,r=1(i-r)!((xA)^i-r)_i,r if r< i and 
		0 otherwise, we have
		
    (ℋ_0)_i,j = ∑_r=1^min{i,j}δ_r^(ν)∫_0^∞ e^-x x^(ν+r)((xA)^i-r)_i,r(i-r)!((xA)^j-r)_j,r(j-r)! dx = ∑_r=1^min{i,j}δ_r^(ν)(A^i-r)_i,r(i-r)!(A^j-r)_j,r(j-r)!∫_0^∞ e^-x x^(ν+i+j-r) dx.

		Notice that (A^i-r)_i,r= ∏_k=r^i-1a_k, and recall that Γ(z+1)=∫_0^∞ e^-x x^z dx, we can write 
		
    (ℋ_0)_i,j= ∑_r=1^min{i,j}δ_r^(ν)/(i-r)!(j-r)!(∏_k=r^i-1 a_k ) (∏_s=r^j-1 a_s) Γ(ν+i+j-r+1).

		
		Taking into account that Γ(z+1)=zΓ(z) we obtain that
		
    (ℋ_0)_i,j = Γ(ν) ∑_r=1^min{i,j}δ_r^(ν)/(i-r)!(j-r)!(∏_k=r^i-1 a_k ) (∏_s=r^j-1 a_s) (ν)_i+j-r,

		as asserted.
	
	
	
		Notice that we also have the expression 
		
    ℋ_0 = (L^(ν)_μ(0))^-1ℋ^(ν,ν)_0 (L^(ν)_μ(0))^∗,
 
		with L^(ν)_μ(0) and  ℋ^(ν,ν)_0 defined 
		in <cit.>, where 
		
    μ=(μ_1, …, μ_N)   such that  a_i=μ_i+1μ_i  for i=1, …, N-1.

		This assertion can be deduced from W^ν(x)= (L^(ν)_μ(0))^-1 W^(ν,ν)(x) (L^(ν)_μ(0))^∗, where W^(ν,ν)(x) are as in <cit.>. 
		They also proved that  ℋ^(ν,ν)_0 is a diagonal matrix.
	
	
	
	The following result gives a recursion for X(n)'s in terms of I(n).
	
	
		For n ≥ 1, let I(n) as in (<ref>).
		If δ_i,j denotes the kronecker delta function, then: 
		
			
  * n δ_1,j + X(n)_1,j+1 a_j - X(n)_1,j = -(n+1+ν)δ_1,j - I(n)_1,j.
			
			
  * n δ_i,j + X(n)_i,j+1 a_j - a_i-1 X(n+1)_i-1,j - X(n)_i,j + X(n+1)_i,j = -(n+1+ν)δ_i,j - I(n)_i,j for i≥ 2.
		
	
	
	
		By Corollary <ref>, we have that
		
    n+X(n)A - A X(n+1)-B(n) = -(n+1+ν)-ℋ(n)Jℋ^-1(n).

		The result is a direct consequense of taking (i,j)-th coordinate in the above equation.
	
	
	
		
			
  * By item (a) of Corollary <ref> we can obtain that G(n)_i,i=X(n)_i,i for any i ≥ 1.
			
  * In order to compute P(x,n), for a given n, we can do the following:
			
				
  * Compute ℋ_n and the explicit form of ℋ_0, ℋ_1 
				using Lemma <ref> and Proposition <ref>.
				
  * Compute G(n) and I(n) using ℋ_n.
				
  * Compute the ξ(n,i,j) using the recursions of Propositions <ref> and <ref>. 
				
  * Then we have R(x,n) and so P(x,n)=K_n R(x,n) e^-xA.
			
		
	
	
	
	

§ MATRIX ENTRIES OF P(X,N) IN TERMS OF LAGUERRE AND DUAL HAHN POLYNOMIALS.

	
	In this section, we will show that under some hypothesis, the ξ(n,i,j)'s can be expressed in terms of dual Hahn polynomials. 
	
	

 §.§  Some technical lemmas

	Let N≥ 1 be a fixed integer and let μ=(μ_1,…,μ_N) be a sequence of non-zero coefficients and α>0.
	Then L_μ^() is the N× N unipotent lower triangular matrix defined by
	
    L^(α)_μ(x)_m,n=μ_m/μ_n L^(α+n)_m-n(x),     m≥ n,
    
    			0    n<m.

	For ν>0 we consider the weight matrix
	
    W^(α,ν)_μ(x)=L_μ^(α)(x) T^(ν)(x) L_μ^(α)(x)^∗,     T^(ν)(x)=e^-x∑_k=1^N x^ν+kδ_k^(ν)  E_k,k.

	It can be showed that
	
    W_μ^(α, ν)(x) = L^(α)_μ(0) e^xA_μ T^(ν)(x) e^xA_μ^∗  L^(α)_μ(0)^∗  where   
    		A_μ=- ∑_k=1^N-1μ_k+1μ_kE_k+1,k.

	We impose conditions on the sequence {μ_i}_i=1^N and the coefficients δ_k^(ν). 
	First of all, we assume that the coefficients μ_i are real and non-zero for all i 
	and δ_k^(ν)>0, 1≤ k≤ N, so that the weight matrix is positive definite 
	(see <cit.> for more information about the weight matrix W^(α,ν)_μ).
	On the other hand, we consider the diagonal matrix Δ^(ν) = diag(δ_1^(ν), …, δ_N^(ν)), so that (T^(ν))_k,k=e^-x x^ν+k (Δ^(ν))_k,k. We assume that there exist coefficients c^(ν) and d^(ν) such that 
	
    Δ^(ν+1)=(d^(ν) J+c^(ν))  Δ^(ν).

	We also assume that the coefficients μ_k and δ^(ν)_k satisfy the  relation
	
    μ_k+1^2μ_k^2=d^(ν)k(N-k) δ_k+1^(ν)δ_k^(ν+1),      k=1,…,N-1.
	
	Under the above conditions, Propositions 5.1 and 5.2 from <cit.> say that 
	
    Φ^(α, ν)(x)=(W_μ^(α, ν)(x))^-1W_μ^(α, ν+1)(x) 
    		  and  Ψ^(α, ν)(x)=(W_μ^(α, ν)(x))^-1dW_μ^(α, ν+1)dx(x)
	
	are matrix polynomials of degree 2 and 1 respectively.
	Moreover, Corollary 6.3 from <cit.> asserts 
	that the operator D_2 defined by 
	
    D_2(x)= d^2dx^2Φ^∗(x) + ddxΨ^∗(x)

	is symmetric respect to W_μ^(α, ν).	
	
	
	We begin with the following technical lemma which relates the matrix polynomials R_n(x) 
	with the constants c^( ν) and d^( ν). The proof of Lemma <ref> and Lemma <ref> can be found in the appendix.
	
		Let μ=(μ_1,…,μ_N) and δ^(ν)_k>0 for 1≤ k≤ N, satisfying (<ref>) and (<ref>).
		Let A:=A_μ as in (<ref>).
		If R(x,n) are the matrix polynomials defined in (<ref>), then
		
    (  R'(0,n)- R(0,n) A)C^(ν)=D^(ν)R(0,n)

		where C^(ν)= (d^(ν)J+c^(ν))(ν+J+1)+ ((Δ^(ν))^-1A Δ^(ν+1))^∗ and
		D^(ν)= n(d^(ν)(J-N-1)-c^(ν))
		with c^( ν) and d^( ν) as in (<ref>).
	
	
	
	
	In the sequel, let 0 ≤ n, 1 ≤ i ≤ N. We consider the sequence ϵ_j:=ϵ_j^(n,i) defined recursively by  
	
    ϵ_0=1,     ϵ_j=(n+i-j+1) d^(ν)((j-1) + c^(ν)d^(ν)) ϵ_j-1  for n+i-j ≥ 0,

	with c^(ν), d^(ν) defined as in (<ref>).    
	We have the following result.
	
	
		Let 0≤ n and let 1 ≤ N, 1 ≤ i ≤ N integers and let {ϵ_l}_l=0^i+n be the sequence defined as in (<ref>). 
		If ν>0, δ^(ν) satisfies (<ref>) and 0 ≤ j < n+i, we have
		
    ϵ_jϵ_j+1M_j=1
    		    where     M_j= (n+i-j) (d^(ν) j + c^(ν))

		with c^(ν), d^(ν) as in (<ref>).
	
	
		It follows by a simple inductive argument from the definition of ϵ_j.
	
	
	Given i=1,…,N, n ≥ 0 and  j a positive integer such that n+i-j ≥ 0, 
	in the sequel we consider the sequence q_j:=q_j^(n,i) by the expression
	
    q_j^(n,i) := ϵ_j^(n,i)ξ(n,i,j),

	where ϵ_j's are as in (<ref>).
	
	
		
		Let μ=(μ_1,…,μ_N) and δ^(ν)_k>0 for 1≤ k≤ N, satisfying (<ref>) and (<ref>). 
		For 1 ≤ i ≤ N and 0 ≤ n, let {q_l}_l=0^i+n be the sequence as in (<ref>).
		Then, the sequence {q_l}_l=0^i+n satisfies
		
    E_j q_j +  F_j  q_j-1 + 1d^(ν)   q_j+1 = 0,    n+i-j > 0,

		where 
		
    E_j    =(n+i-j) ( j + c^(ν)d^(ν)) +  (j-1) (N-j+1) + n  ( (i-N-1)-c^(ν)d^(ν)) ,
    
    			F_j    =(j-1) (N-j+1) μ_j-1μ_j  (n+i-j+1)  (d^(ν) (j-1) + c^(ν))

		with c^(ν), d^(ν) as in (<ref>).
	
	
	

 §.§ Dual Hahn polynomials

	
	For 0 ≤ n, 1 ≤ i ≤ N let us consider the following sequence 
	
    q_j^(n,i):= (d^(ν))^-j q_j^(n,i),    n+i-j > 0,
where q_j's are as in (<ref>) and d^(ν) as (<ref>).
	
	
	
		Let μ=(μ_1,…,μ_N) and 0 < δ^(ν)_k, for 1≤ k≤ N, satisfying (<ref>) and (<ref>). 
		Let q_l be  as in (<ref>).
		If μ_j=1 for all j then the q_l's satisfy the following equation
		
    E_j q_j+ F_j  q_j-1 +  q_j+1 = 0,    n+i-j > 0,

		where
		
    E_j    =(n+i-j) ( j + c^(ν)d^(ν)) +  (j-1) (N-j+1) + n  ( i-N-1-c^(ν)d^(ν)), 
    F_j    = (j-1) (N-j+1)  (n+i-j+1)  (j-1 + c^(ν)d^(ν))

		with c^(ν), d^(ν) as in (<ref>).
	
	
		By Lemma <ref>, we have that E_j q_j +  F_j  q_j-1 + 1d^(ν)   q_j+1 = 0
		with 
		
    E_j    =(n+i-j) ( j + c^(ν)d^(ν)) +  (j-1) (N-j+1) + n  ( (i-N-1)-c^(ν)d^(ν)) ,
    
    				F_j    =(j-1) (N-j+1) μ_j-1μ_j  (n+i-j+1)  (d^(ν) (j-1) + c^(ν)).

		Now, since μ_j=1 for all j and  q_j(x):= (d^(ν))^-j q_j(x),
		we have that
		
    ((n+i-j) ( j + c^(ν)d^(ν)) +  (j-1) (N-j+1) + n  ( (i-N-1)-c^(ν)d^(ν)) ) q_j(d^(ν))^j
       +     (j-1) (N-j+1)  (n+i-j+1)  (d^(ν) (j-1) + c^(ν)) (d^(ν))^j-1q_j-1 + 1d^(ν)(d^(ν))^j+1q_j+1 = 0.

		By multiplication for (d^(ν))^-j, we obtain that
		
    E_j q_j+ F_j  q_j-1 +  q_j+1 = 0,

		with
		
    E_j    =(n+i-j) ( j + c^(ν)d^(ν)) +  (j-1) (N-j+1) + n  ( i-N-1-c^(ν)d^(ν)), 
    F_j    = (j-1) (N-j+1)  (n+i-j+1)  (j-1 + c^(ν)d^(ν)),

		as asserted.
	
	
	Recall that if the sequence of polynomials  {s_k} satisfies the normalized recurrence relations 
	
    xs_k(x)= s_k+1(x) -(u_k+v_k) s_k(x)+u_k-1v_k s_k-1(x),

	with 
	
    u_k=(k+γ+1)(k-M),      v_k=k(k-δ-M-1),

	then s_k satisfies 
	
    T_k(λ(x);γ,δ,M) = 1(γ+1)_k (-M)_k s_k(λ(x))
 
	where λ(x)= x(x+γ+δ +1) and {T_k} is the sequence of dual Hahn polynomials defined by
	
    T_k(λ(x);γ,δ,M)=  _3 F_2(-k,      -x,      x+γ+δ+1
          γ+1,      -M   ;1)     for  k=0,1,…,M.

	
		Let μ=(μ_1,…,μ_N) and δ^(ν)_k>0 for 1≤ k≤ N, satisfying (<ref>) and (<ref>). 
		Let q_j be  as in (<ref>).
		If μ_ℓ=1 for all ℓ=1,…,N, then the q_j's satisfy
		
    q_j= (γ+1)_j-1(-(N-1))_j-1 T_j-1(λ(x^(n,i)); γ,δ, N-1)    n+i-j > 0

		where γ= c^(ν)d^(ν),  δ=n+i-N and x^(n,i)=(γ+1)(N+i-2)-n(N-i).
	
	
		By Lemma <ref>, we have that
		
    E_j q_j+ F_j  q_j-1 +  q_j+1 = 0,    n+i-j > 0,

		where
		
    E_j    =(n+i-j) ( j + c^(ν)d^(ν)) +  (j-1) (N-j+1) + n  ( i-N-1-c^(ν)d^(ν)), 
    F_j    = (j-1) (N-j+1)  (n+i-j+1)  (j-1 + c^(ν)d^(ν))

		with c^(ν), d^(ν) as in (<ref>). Now, if we consider
		
    u_k=(k+γ+1)(k-M) and  v_k=k(k-δ-M-1),

		with γ= c^(ν)d^(ν), δ=n+i-N and M=N-1. It is straightforward to check that
		
    F_j = u_j-2 v_j-1  and  E_j = -(u_j-1+v_j-1+x^(n,i))
	
		where x^(n,i)=(γ+1)(N+i-2)-n(N-i). 
		Thus, since q_j can be seen as constants polynomial, 
		we have that
		
    x^(n,i)q_j(x^(n,i)) = 
    		q_j+1(x^(n,i)) -(u_j-1+v_j-1) q_j(x^(n,i))+u_j-2 v_j-1q_j-1(x^(n,i)).

		Therefore, by definition of dual Hahn polynomials and by taking into account that q_j is a constant polynomial, we obtain (<ref>) as desired.
	
	
	
	By recalling that q_j=(d^(ν))^-j q_j = ϵ_j (d^(ν))^-jξ(n,i,j) for n+i-j > 0, we obtain the following result
	
	
		Let μ=(μ_1,…,μ_N) and δ^(ν)_k > 0, for 1≤ k≤ N, satisfying (<ref>) and (<ref>). Let ϵ_j as in (<ref>).
		If μ_ℓ=1 for all ℓ=1,…,N, then the constants ξ(n,i,j)'s satisfy
		
    ξ(n,i,j)= (d^(ν))^j(γ+1)_j-1(-(N-1))_j-1ϵ_j T_j-1(λ(x^(n,i)); γ,δ, N-1),    n+i-j > 0

		where γ= c^(ν)d^(ν),  δ=n+i-N and x^(n,i)=(γ+1)(N+i-2)-n(N-i).
		Moreover, if n+i=j, the constants ξ(n,i,j)'s satisfy the recursion	
		
    ξ(0,1,1)=1ν +2,     ξ(n,i,j-1) =
    			( n(N+1-i)(i-1)(j-1) (N-j+1) + 1 )ξ(n,i,j),    j >1,

		
	
	
		If n+i-j > 0, by Proposition <ref> we have that 
		
    ξ(n,i,j)=(d^(ν))^jϵ_jq_j= (d^(ν))^j(γ+1)_j-1(-(N-1))_j-1ϵ_j T_j-1(λ(x^(n,i)); γ,δ, N-1)

		with γ= c^(ν)d^(ν),  δ=n+i-N and x^(n,i)=(γ+1)(N+i-2)-n(N-i) as asserted.	
		
		Now, if we take j=n+i in the expression (<ref>), we obtain
		
    R_n'(0)_i,j (d^(ν) j + c^(ν)) (ν + j +1)  + R_n'(0)_i(j-1)((Δ^(ν))^-1A Δ^(ν+1))^∗_(j-1)j
           - (R_n(0)_i,j A_j(j-1)((Δ^(ν))^-1A Δ^(ν+1))^∗_(j-1),j = n(d^(ν)(J-N-1)-c^(ν)) R(n,0)_i,j.

		
		
		
		By taking into account that R_n(x)_i,j=L^(ν+j)_n+i-j(x) ξ(n,i,j), 
		
    L^α_n(0)=(α+1)_nn!    and    ∂∂ xL^α_n(x)=(-1) L^α+1_n-1(x),

		we have
		
    - ξ(n,i,j-1) ((Δ^(ν))^-1A Δ^(ν+1))^∗_(j-1)j   -    (ξ(n,i,j) A_j(j-1)((Δ^(ν))^-1A Δ^(ν+1))^∗_(j-1),j
       =    n(d^(ν)(i-N-1)-c^(ν)) ξ(n,i,j).

		Recall that by (<ref>) we have that
		
    ((Δ^(ν))^-1 A Δ^(ν+1))^∗_(j-1,j) = d^(ν) (j-1) (N-j+1) μ_j-1μ_j,

		then, taking in account that μ_k=1 for all k, we have
		
    - ξ(n,i,j-1) d^(ν) (j-1) (N-j+1)     -    (ξ(n,i,j) A_j(j-1)d^(ν) (j-1) (N-j+1) 
       =    n(d^(ν)(i-N-1)-c^(ν)) ξ(n,i,j).

		
		Thus, using the conditions (<ref>), (<ref>), and taking in account that A_s,s-1=-1, we obtain
		
    - d^(ν) (j-1) (N-j+1) ξ(n,i,j-1) =
    				(-nd^(ν)(N+1-i)(i-1) - d^(ν) (j-1) (N-j+1) )ξ(n,i,j),

		as desired.
		
		The last assertion it follows from 
    ξ(0,1,1)(ν +2)=ξ(0,1,1) L^1_1(0)=R(0,0)_1,1=(K_1 P(0,0))_1,1=1

		
	
	
	
	plain
			
	
	

§ 

	
	In this apprendix we give the proofs of the  Lemmas <ref> and <ref>.
	
	
		Let P_n(x)=P(x,n) be the sequence of monic orthogonal polynomials 
		respect to the weight W^(ν) as in (<ref>).
		Since W_μ^(α, ν)(x)=L_μ^(α)(0) W^(ν)(x) L_μ^(α)(0)^* we have that 
		
    ∫_0^∞ P_n(x) (L_μ^(α)(0)^-1)W_μ^(α, ν)(x) (P_m(x)L_μ^(α)(0)^-1)^* dx =∫_0^∞ P_n(x) W^(ν)(x) P_m(x)^* dx= δ_n,mℋ_n.

		Hence, if P_n^(α,ν)(x)=L_μ^(α)(0) P_n(x) L_μ^(α)(0)^-1 then  
		P^(α,ν)_n(x) is the sequence of monic orthogonal polynomials with respect to the weight W_μ^(α, ν).
		Now, if D_2 is the operator defined in (<ref>), the Corollary 6.3 of <cit.> implies that
		P^(α,ν)_n D_2= n K̂_n^(α,ν) P^(α,ν)_n 
		for certain matrix K̂_n^(α,ν) defined recursively in section 6 from <cit.>, and so 
		
    P_n L_μ^(α)(0)^-1D_2 L_μ^(α)(0)=nL_μ^(α)(0)^-1K̂_n^(α,ν) L_μ^(α)(0) P_n.

		By Proposition 6.1 of <cit.>, we obtain that
		
    (L_μ^(α)(0))^-1K̂_n^(α,ν) L_μ^(α)(0)=d^(ν)(J-(J+ν+n)A-N-1)-c^(ν),
 
		and by taking into account that JA-AJ=A, we have that
		
    J-JA-(ν+n)A-N-1=J-AJ-A-(ν+n)A-N-1.

		On the other hand, since Γ_n=A(n+ν+J+1)-(n+J)=-J+(n+ν)A+A+AJ-n, then
		
    (L_μ^(α)(0))^-1K̂_n^(α,ν) L_μ^(α)(0)=d^(ν)(-Γ_n-n-N-1)-c^(ν).

		By (<ref>), we have that
		
    K_n R_n e^-xA(L_μ^(α)(0))^-1D_2 L_μ^(α)(0)= n (L_μ^(α)(0))^-1K̂_n^(α,ν) L_μ^(α)(0)K_n R_n e^-xA

		and thus
		
    R_n e^-xA(L_μ^(α)(0))^-1D_2 L_μ^(α)(0)e^xA=n K_n^-1(d^(ν)(-Γ_n-n-N-1)-c^(ν))K_n R_n.

		By recalling that K_n^-1Γ_n K_n =-n-J, we have that
		
    R_n e^-xA(L_μ^(α)(0))^-1D_2 L_μ^(α)(0)e^xA=n(d^(ν)(J-N-1)-c^(ν))R_n.

		Now, by taking into account that D_2= d^2dx^2Φ^∗(x) + ddxΨ^∗(x) with Φ, Ψ polynomials of degree 2 and 1. In general, if U(x) is a polynomial, we have that
		
    U(x) · e^-xA(L_μ^(α)(0))^-1D_2 L_μ^(α)(0)e^xA    =    d^2dx^2( U(x) e^-xA) (L_μ^(α)(0))^-1Φ^∗(x) L_μ^(α)(0)e^xA
           + ddx( U(x) e^-xA) (L_μ^(α)(0))^-1Ψ^∗(x) L_μ^(α)(0)e^xA
        =    ( U”(x)-2 U'(x)A+ U(x) A^2) e^-xA(L_μ^(α)0))^-1Φ^∗(x) L_μ^(α)(0)e^xA
           + (  U'(x)- U(x) A) e^-xA(L_μ^(α)(0))^-1Ψ^∗(x) L_μ^(α)(0)e^xA.

		Hence, we want to find some easy expression for
		
    e^-xA L(0)^-1Φ^∗(x) L(0) e^xA  and   e^-xA L(0)^-1Ψ^∗(x) L(0) e^xA.

		Some similar expressions was studied by Koelink and Roman (see <cit.>).
		By Corollary 5.3 in <cit.>, we have that
		
		 
    L_μ^(α)(0)^∗Φ(x) ((L_μ^(α)(0))^∗)^-1   =     -d^(ν)x^2 A^∗+x (d^(ν) J +c^(ν))
    
    				L_μ^(α)(0)^∗Ψ(x) ((L_μ^(α)(0))^∗)^-1    =     x(d^(ν)(J-A^∗(J+ν+1) -N-1)-c^(ν)) ) 
           + (ν+J+1)(d^(ν)J+c^(ν))+(Δ^(ν))^-1A Δ^(ν+1).

		Hence, we have that
		
    e^-xAL_μ^(α)(0)^-1Φ^∗(x)L_μ^(α)(0) e^xA   =    -d^(ν)x^2 e^-xAA e^xA+xd^(ν)e^-xAJe^xA+x c^(ν)
       =    -d^(ν)x^2 A +xd^(ν)(xA+J)+ xc^(ν)
       =    x(d^(ν)J+c^(ν)).

		
    e^-xAL_μ^(α)(0)^-1Ψ^∗(x)L_μ^(α)(0) e^xA   =    x(d^(ν)(xA+J-(xA+J+ν+1)A-N-1)-c^(ν)) ) 
           + (d^(ν)(xA+J)+c^(ν))(ν+xA+J+1)+e^-xA ((Δ^(ν))^-1A Δ^(ν+1))^∗ e^xA.

		By evaluation in x=0 in (<ref>) and by taking into account the above expressions, 
		we obtain (<ref>), as desired.
	
	
	
	
		By taking into account that (R_n(x))_i,j satisfies the expression given by Theorem <ref>, the (i,j)-coordinate of the matrix in the right hand of (<ref>) is 
		
    n(d^(ν)(i-N-1)-c^(ν))(R_n(0))_i,j= n(d^(ν)(i-N-1)-c^(ν))L^(ν+j)_n+i-j(0) ξ(n,i,j).

		On the other hand, for n+i-j > 0 the (i,j)-coordinate of the matrix in the left hand of (<ref>) is
		
    R_n'(0)_i,j (d^(ν) j + c^(ν)) (ν + j +1)  + R_n'(0)_i(j-1)((Δ^(ν))^-1A Δ^(ν+1))^∗_(j-1)j
           - R_n(0)_i(j+1) (d^(ν) j + c^(ν)) (ν + j +1) A_(j+1)j  - (R_n(0)_i,j A_j(j-1)((Δ^(ν))^-1A Δ^(ν+1))^∗_(j-1),j.

		By taking into account that R_n(x)_i,j=L^(ν+j)_n+i-j(x) ξ(n,i,j), 
		
    L^α_n(0)=(α+1)_nn!    and    ∂∂ xL^α_n(x)=(-1) L^α+1_n-1(x),

		we obtain that the above expression is equivalent to
		
    - n (d^(ν) (i-N-1)-c^(ν)) (ν+j+1)_n+i-j(n+i-j)!ξ(n,i,j)    =   (ν+j+2)_n+i-j-1(n+i-j-1)! (d^(ν) j + c^(ν)) (ν +j +1) ξ(n,i,j)
           + (ν+j+1)_n+i-j(n+i-j)!( (Δ^(ν))^-1 A Δ^(ν+1))^∗_(j-1,j)ξ(n,i,j-1)
           + (ν+j+2)_n+i-j-1(n+i-j-1)! (d^(ν) j + c^(ν)) (ν+j+1) ξ(n,i,j+1)
           + (ν+j+1)_(n+i-j)(n+i-j)! A_j(j-1)((Δ^(ν))^-1 A Δ^(ν))^∗_(j-1)jξ(n,i,j).

		Thus, by taking into account that (ν+j+2)_n+i-j-1(ν +j +1)= (ν+j+1)_n+i-j-1, and  multiplying both sides by (n+i-j-1)!(ν+j+1)_n+i-j-1, we obtain 
		
    - n (d^(ν) (i-N-1)-c^(ν)) (n+i-j-1)n+i-jξ(n,i,j)    =     (d^(ν) j + c^(ν)) ξ(n,i,j)
          +   (n+i-j-1)n+i-j( (Δ^(ν))^-1 A Δ^(ν+1))^∗_(j-1,j)ξ(n,i,j-1)
           +   (d^(ν) j + c^(ν)) ξ(n,i,j+1)
          + (n+i-j-1)n+i-j A_j(j-1)((Δ^(ν))^-1 A Δ^(ν))^∗_(j-1)jξ(n,i,j).

		Finally, we obtain that 
		
    ((n+i-j)(d^(ν) j + c^(ν)) + A_j(j-1)((Δ^(ν))^-1 A Δ^(ν))^∗_(j-1)j + n (d^(ν) (i-N-1)-c^(ν)) ) ξ(n,i,j)
           + ( (Δ^(ν))^-1 A Δ^(ν+1))^∗_(j-1,j)ξ(n,i,j-1) +  (n+i-j) (d^(ν) j + c^(ν)) ξ(n,i,j+1) = 0.

		By (<ref>) we have that δ^(ν)_k+1δ^(ν+1)_k = μ_k+1^2d^(ν) k (N-k) μ_k^2,
		and then
		
    ((Δ^(ν))^-1 A Δ^(ν+1))^∗_(j-1,j)   =   δ^(ν+1)_j-1δ^(ν)_j A_j(j-1)
       =    d^(ν) (j-1) (N-j+1) μ_j-1^2μ_j^2μ_jμ_j-1
       =    d^(ν) (j-1) (N-j+1) μ_j-1μ_j.

		Thus, we can rewrite the above equation as follows 
		
    ((n+i-j)(d^(ν) j + c^(ν)) + d^(ν) (j-1) (N-j+1) + n (d^(ν) (i-N-1)-c^(ν)) ) ξ(n,i,j)
           + d^(ν) (j-1) (N-j+1) μ_j-1μ_jξ(n,i,j-1) +  (n+i-j) (d^(ν) j + c^(ν)) ξ(n,i,j+1) = 0.

		Now, if we consider M_j=(n+i-j) (d^(ν) j + c^(ν)). 
		Since ϵ^(n,i)_j ξ(n,i,j) = q_j^(n,i),
		we can rewrite the above equation as follows
		
    ((n+i-j)(d^(ν) j + c^(ν)) + d^(ν) (j-1) (N-j+1) + n (d^(ν) (i-N-1)-c^(ν)) ) q_jϵ_j
     
    				+ d^(ν) (j-1) (N-j+1) μ_j-1μ_jq_j-1ϵ_j-1 +  M_j q_j+1ϵ_j+1 = 0.

		If we multiply by ϵ_j, we have that
		
    ((n+i-j)(d^(ν) j + c^(ν)) + d^(ν) (j-1) (N-j+1) + n (d^(ν) (i-N-1)-c^(ν)) ) q_j 
     
    				+ d^(ν) (j-1) (N-j+1) μ_j-1μ_jϵ_jϵ_j-1 q_j-1 +  M_j ϵ_jϵ_j+1 q_j+1 = 0.

		By Lemma <ref>, we have that M_j ϵ_jϵ_j+1 =1 and so we obtain 
		
    d^(ν)((n+i-j)( j + c^(ν)d^(ν)) +  (j-1) (N-j+1) + n  ( (i-N-1)-c^(ν)d^(ν)) ) q_j 
       +    d^(ν) (j-1) (N-j+1) μ_j-1μ_j  (n+i-j+1)  (d^(ν) (j-1) + c^(ν))  q_j-1 +   q_j+1 = 0,

		which is equivalent to 
		
    E_j q_j +  F_j  q_j-1 + 1d^(ν)   q_j+1 = 0,

		with
		
    E_j    =(n+i-j) ( j + c^(ν)d^(ν)) +  (j-1) (N-j+1) + n  ( (i-N-1)-c^(ν)d^(ν)),
    
    				F_j    =(j-1) (N-j+1) μ_j-1μ_j  (n+i-j+1)  (d^(ν) (j-1) + c^(ν)),

		as asserted.
	
	
	
