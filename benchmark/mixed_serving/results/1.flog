Warning: MLC is not installed. Related functionalities will be disabled.
Namespace(dataset='../workloads/sharegpt/ShareGPT_V3_unfiltered_cleaned_split.json', tokenizer='hf-internal-testing/llama-tokenizer', num_prompts=100, request_rate=4.0, seed=0, trust_remote_code=False)
INFO 12-07 05:28:51 tokenizer.py:27] For some LLaMA-based models, initializing the fast tokenizer may take a long time. To eliminate the initialization time, consider using 'hf-internal-testing/llama-tokenizer' instead of the original tokenizer.
Total time: 87.38 s
Throughput: 1.14 requests/s
Average latency: 30410.33 ms
Average latency per token: 100.08 ms
Average latency per output token: 628.87 ms
